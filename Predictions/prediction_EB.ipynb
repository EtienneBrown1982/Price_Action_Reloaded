{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from alpaca.data.requests import StockBarsRequest\n",
    "from alpaca.data.historical.stock import StockHistoricalDataClient\n",
    "from alpaca.data.timeframe import TimeFrame, TimeFrameUnit\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Reshape\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env file\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Alpaca API key and secret\n",
    "\n",
    "ALPACA_API_KEY = os.getenv(\"ALPACA_API_KEY\")\n",
    "ALPACA_SECRET_KEY = os.getenv(\"ALPACA_API_SECRET\")\n",
    "client = StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_SECRET_KEY)\n",
    "\n",
    "# Create the Alpaca API object\n",
    "\n",
    "timeframe = TimeFrame(1, TimeFrameUnit.Day)\n",
    "symbol = 'SPY'\n",
    "start = datetime.utcnow() - timedelta(days=3650)\n",
    "end=datetime.utcnow() - timedelta(days=730)\n",
    "request = StockBarsRequest(symbol_or_symbols=symbol, start=start, end=end, timeframe=timeframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = client.get_stock_bars(request).df.tz_convert('America/New_York', level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(source_df.head())\n",
    "display(source_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_df = source_df.copy()\n",
    "# pct_change is profit from last close\n",
    "bars_df[\"pct_change\"] = bars_df[\"close\"].pct_change()\n",
    "# signal for when we want to be in or out of a stock\n",
    "#bars_df[\"signal\"] = np.where(bars_df[\"pct_change\"] > 0, 1.0, 0.0)\n",
    "# reaction is the signal diff\n",
    "#bars_df[\"reaction\"] = bars_df[\"signal\"].diff()\n",
    "# action is if we could perfectly predict the next close\n",
    "#bars_df[\"action\"] = bars_df[\"reaction\"].shift(-1)\n",
    "# these values are the high, low, and open as a percentage of the current close\n",
    "bars_df[\"high %\"] = (bars_df[\"high\"] - bars_df[\"close\"])/bars_df[\"close\"]\n",
    "bars_df[\"low %\"] = (bars_df[\"low\"] - bars_df[\"close\"])/bars_df[\"close\"]\n",
    "bars_df[\"open %\"] = (bars_df[\"open\"] - bars_df[\"close\"])/bars_df[\"close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup DF for model\n",
    "\n",
    "bars_df = bars_df.droplevel(level=0).dropna()\n",
    "bars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data set\n",
    "\n",
    "scaler = StandardScaler()\n",
    "bars_df_scaled = scaler.fit_transform(bars_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "\n",
    "# input shape\n",
    "\n",
    "input_shape = bars_df_scaled.shape[1]\n",
    "latent_dim = 11\n",
    "num_samples = bars_df_scaled.shape[0]\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator (Sequential)\n",
    "\n",
    "build_generator = Sequential([\n",
    "    Dense(128,input_shape=(input_shape,), activation=\"relu\"),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dense(512, activation=\"relu\"),\n",
    "    Dense(input_shape, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Define descriminator\n",
    "\n",
    "build_discriminator = Sequential([\n",
    "    Dense(512, input_shape=(input_shape,), activation=\"relu\"),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile generator\n",
    "build_generator.compile(loss = \"mse\", optimizer=\"adam\")\n",
    "\n",
    "# Compile discriminator\n",
    "build_discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine models\n",
    "\n",
    "# Confirm that discriminator weights are not training during generators training\n",
    "\n",
    "build_discriminator.trainable=False\n",
    "\n",
    "# Setup for generators data\n",
    "\n",
    "z = tf.keras.Input(shape=(latent_dim,))\n",
    "\n",
    "# Generated data by the generator\n",
    "\n",
    "generated_data = build_generator(z)\n",
    "\n",
    "# Discriminators verdict\n",
    "\n",
    "validity = build_discriminator(generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combined models\n",
    "\n",
    "combined = tf.keras.Model(z, validity)\n",
    "combined.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Print summary of the combined model\n",
    "combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training loop\n",
    "\n",
    "epochs = 10000\n",
    "\n",
    "generator_weights_path = \"./generator_model.h5\"\n",
    "discriminator_weights_path = \"./discriminator_model.h5\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Train discriminator\n",
    "    # Sample real data\n",
    "    idx = np.random.choice(num_samples, batch_size, replace=False)\n",
    "    real_data = bars_df_scaled[idx]\n",
    "\n",
    " # Generate fake data (Random Walk noise)\n",
    "\n",
    "    gaussian_noise = np.random.normal(0,1,size=(batch_size,input_shape))\n",
    "    random_walk_noise = np.cumsum(gaussian_noise, axis=0)\n",
    "\n",
    "    fake_data = build_generator.predict(random_walk_noise)\n",
    "\n",
    "    # Train discriminator\n",
    "\n",
    "    d_loss_real = build_discriminator.train_on_batch(real_data, np.ones((batch_size, 1)))\n",
    "    d_loss_fake = build_discriminator.train_on_batch(fake_data, np.zeros((batch_size, 1)))\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "    \n",
    "    # Train generator \n",
    "\n",
    "    noise = np.random.normal(0, 1, (batch_size, input_shape))\n",
    "    g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "    \n",
    "    # Print progress\n",
    "\n",
    "    print(f\"Epoch {epoch}, Discriminator Loss: {d_loss}, Generator Loss: {g_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Model Weights\n",
    "\n",
    "build_generator.save(\"generator_model.h5\")\n",
    "build_discriminator.save(\"discriminator_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create alpaca object for testing\n",
    "\n",
    "timeframe = TimeFrame(1, TimeFrameUnit.Day)\n",
    "symbol = 'SPY'\n",
    "start = datetime.utcnow() - timedelta(days=730)\n",
    "end=datetime.utcnow() - timedelta(days=1)\n",
    "request = StockBarsRequest(symbol_or_symbols=symbol, start=start, end=end, timeframe=timeframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df for testing\n",
    "\n",
    "test_df = client.get_stock_bars(request).df.tz_convert('America/New_York', level=1)\n",
    "\n",
    "# data preprocessing for testing\n",
    "\n",
    "# pct_change is profit from last close\n",
    "test_df[\"pct_change\"] = test_df[\"close\"].pct_change()\n",
    "# signal for when we want to be in or out of a stock\n",
    "#bars_df[\"signal\"] = np.where(bars_df[\"pct_change\"] > 0, 1.0, 0.0)\n",
    "# reaction is the signal diff\n",
    "#bars_df[\"reaction\"] = bars_df[\"signal\"].diff()\n",
    "# action is if we could perfectly predict the next close\n",
    "#bars_df[\"action\"] = bars_df[\"reaction\"].shift(-1)\n",
    "# these values are the high, low, and open as a percentage of the current close\n",
    "test_df[\"high %\"] = (test_df[\"high\"] - test_df[\"close\"])/test_df[\"close\"]\n",
    "test_df[\"low %\"] = (test_df[\"low\"] - test_df[\"close\"])/test_df[\"close\"]\n",
    "test_df[\"open %\"] = (test_df[\"open\"] - test_df[\"close\"])/test_df[\"close\"]\n",
    "\n",
    "# set timestamp as index, drop nan\n",
    "\n",
    "test_df = test_df.droplevel(level=0).dropna()\n",
    "\n",
    "test_df.info()\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize test data set\n",
    "\n",
    "test_df_scaled = scaler.fit_transform(test_df)\n",
    "\n",
    "print(test_df_scaled)\n",
    "print(len(test_df_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test generator against real data\n",
    "\n",
    "#lists to store generated and timestamps\n",
    "\n",
    "column_names=[\n",
    "    \"Predicted Open\",\n",
    "    \"Predicted High\",\n",
    "    \"Predicted Low\",\n",
    "    \"Predicted Close\",\n",
    "    \"Predicted Volume\",\n",
    "    \"Predicted Trade Count\",\n",
    "    \"Predicted VWAP\",\n",
    "    \"Predicted pct_change\",\n",
    "    \"Predicted high %\",\n",
    "    \"Predicted low %\",\n",
    "    \"Predicted open %\"\n",
    "    ]\n",
    "\n",
    "# sliding window\n",
    "\n",
    "window_size = 1\n",
    "\n",
    "# init lists to store generated data with associated timestamps\n",
    "\n",
    "timestamps = []\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of scaled test data\n",
    "\n",
    "print(test_df_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "predictions_df[:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.index)\n",
    "print(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction loop\n",
    "\n",
    "for i in range(0,len(test_df_scaled),window_size):\n",
    "    print(i)\n",
    "    # extract sliding window of real data\n",
    "\n",
    "    input_data = test_df_scaled[i:i+window_size]\n",
    "\n",
    "    # predict the next row using generator\n",
    "\n",
    "    shaped_data = input_data.reshape(1,window_size,11)\n",
    "    print(shaped_data)\n",
    "\n",
    "    predicted_row = build_generator.predict(shaped_data)\n",
    "    \n",
    "    #predicted_row = build_generator.predict(input_data)\n",
    "\n",
    "    #append generated row to list\n",
    "    # predictions.append(predicted_row)\n",
    "\n",
    "    # extract timestamp for the prediction\n",
    "\n",
    "    if (i + window_size) < len(test_df):\n",
    "        timestamp = test_df.index[i+window_size]\n",
    "    else:\n",
    "        timestamp = test_df.index[-1] + timedelta(days=1)\n",
    "    \n",
    "    print(timestamp)\n",
    "    print(predicted_row.squeeze())\n",
    "    predictions_df.loc[timestamp] = predicted_row.squeeze()\n",
    "    print(predictions_df.head())\n",
    "    \n",
    "\n",
    "    # predictions_df = pd.concat([predictions_df,predicted_row],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = predictions_df.index\n",
    "\n",
    "predictions_df_inverse_scaled = scaler.inverse_transform(predictions_df)\n",
    "generated_data_df = pd.DataFrame(predictions_df_inverse_scaled, columns=column_names,index=index)\n",
    "generated_data_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_df = pd.concat([test_df,generated_data_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_shift_df = test_df.copy()\n",
    "\n",
    "test_shift_df = test_shift_df.rename(columns={\n",
    "    \"open\": \"next open\",\n",
    "    \"high\": \"next high\",\n",
    "    \"low\": \"next low\",\n",
    "    \"close\": \"next close\",\n",
    "    \"volume\": \"next volume\",\n",
    "    \"trade_count\": \"next trade_count\",\n",
    "    \"vwap\": \"next vwap\",\n",
    "    \"pct_change\": \"next pct_change\",\n",
    "    \"high %\": \"next high %\",\n",
    "    \"low %\": \"next low %\",\n",
    "    \"open %\": \"next open %\"\n",
    "})\n",
    "\n",
    "test_shift_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_shift_df = test_shift_df.shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_df = bars_df.dropna()\n",
    "bars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_df = pd.concat([bars_df,test_shift_df],axis=1)\n",
    "bars_df = bars_df.dropna()\n",
    "bars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_df[\"High/Low Success\"] = np.where(\n",
    "    (bars_df[\"next close\"] >= bars_df[\"Predicted Low\"]),\n",
    "    np.where(\n",
    "        bars_df[\"close\"] <= bars_df[\"Predicted High\"], 1, 0\n",
    "    ), 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_df[\"Predicted Close Delta\"] = bars_df[\"Predicted Close\"] - bars_df[\"close\"]\n",
    "bars_df[\"Next Close Delta\"] = bars_df[\"next close\"] - bars_df[\"close\"]\n",
    "bars_df[\"Close Product\"] = bars_df[\"Next Close Delta\"] * bars_df[\"Predicted Close Delta\"]\n",
    "bars_df[\"Close Success\"] = np.where(\n",
    "    bars_df[\"Close Product\"] >= 0, 1, 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_df = bars_df.rename_axis(\"Date\")\n",
    "bars_df.reset_index(inplace=True)\n",
    "bars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_close = bars_df.hvplot.line(\n",
    "    x=\"Date\",\n",
    "    y=\"next close\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_high = bars_df.hvplot.line(\n",
    "    x=\"Date\",\n",
    "    y=\"Predicted high\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_low = bars_df.hvplot.line(\n",
    "    x=\"Date\",\n",
    "    y=\"Predicted low\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_close = bars_df.hvplot.line(\n",
    "    x=\"Date\",\n",
    "    y=\"Predicted close\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_close * predicted_high * predicted_low * predicted_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_df[\"Action\"] = np.where(\n",
    "    bars_df[\"next close\"] > bars_df[\"close\"], 1, -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(bars_df.head())\n",
    "display(bars_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_position = 0\n",
    "starting_cash = 1000\n",
    "current_cash = starting_cash\n",
    "max_position = 50\n",
    "for index, row in bars_df.iterrows():\n",
    "    # Get the current action\n",
    "    close = row[\"close\"]\n",
    "    action = row[\"Action\"]\n",
    "\n",
    "    # Take the action if possible\n",
    "    if action > 0:\n",
    "        if action + current_position <= max_position and action * close < current_cash:\n",
    "            current_position += action\n",
    "            current_cash -= action*close\n",
    "        else:\n",
    "            action = 0\n",
    "    elif action < 0:\n",
    "        if action + current_position >= 0:\n",
    "            current_position += action\n",
    "            current_cash += -action*close\n",
    "        else:\n",
    "            action = 0\n",
    "\n",
    "    # Update enabled and position\n",
    "    bars_df.loc[index, \"Position\"] = current_position\n",
    "    bars_df.loc[index, \"Cash\"] = current_cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Holdings\n",
    "bars_df[\"Holdings\"] = bars_df[\"close\"] * bars_df[\"Position\"]\n",
    "\n",
    "# Compute Profit\n",
    "bars_df[\"Strategy Value\"] = bars_df[\"Holdings\"] + bars_df[\"Cash\"]\n",
    "starting_close = bars_df.iloc[0][\"close\"] \n",
    "display(f\"starting_close {starting_close}\")\n",
    "starting_shares = math.floor(starting_cash / starting_close)\n",
    "display(f\"starting_shares {starting_shares}\")\n",
    "bars_df[\"Stock Value\"] =  bars_df[\"close\"] * starting_shares\n",
    "\n",
    "# Compute Returns\n",
    "bars_df[\"Stock Returns\"] = bars_df[\"close\"].pct_change()\n",
    "bars_df[\"Strategy Returns\"] = bars_df[\"Strategy Value\"].pct_change()\n",
    "\n",
    "# Compute Cumulative Daily Returns\n",
    "bars_df[\"Stock Cumulative Returns\"] = (bars_df[\"Stock Returns\"] + 1).cumprod()\n",
    "bars_df[\"Strategy Cumulative Returns\"] = (bars_df[\"Strategy Returns\"] + 1).cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_cumulative_returns = bars_df.hvplot.line(\n",
    "    x=\"Date\",\n",
    "    y=\"Stock Cumulative Returns\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_cumulative_returns = bars_df.hvplot.line(\n",
    "    x=\"Date\",\n",
    "    y=\"Strategy Cumulative Returns\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_cumulative_returns * strategy_cumulative_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash = bars_df.hvplot.line(\n",
    "    x=\"Date\",\n",
    "    y=\"Cash\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings = bars_df.hvplot.line(\n",
    "    x=\"Date\",\n",
    "    y=\"Holdings\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash*holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = bars_df.hvplot.line(\n",
    "    x=\"Date\",\n",
    "    y=\"Position\",\n",
    ")\n",
    "position"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
