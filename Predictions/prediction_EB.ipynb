{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from alpaca.data.requests import StockBarsRequest\n",
    "from alpaca.data.historical.stock import StockHistoricalDataClient\n",
    "from alpaca.data.timeframe import TimeFrame, TimeFrameUnit\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load .env file\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Alpaca API key and secret\n",
    "\n",
    "ALPACA_API_KEY = os.getenv(\"ALPACA_API_KEY\")\n",
    "ALPACA_SECRET_KEY = os.getenv(\"ALPACA_API_SECRET\")\n",
    "client = StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_SECRET_KEY)\n",
    "\n",
    "# Create the Alpaca API object\n",
    "\n",
    "timeframe = TimeFrame(1, TimeFrameUnit.Day)\n",
    "symbol = 'SPY'\n",
    "start = datetime.utcnow() - timedelta(days=1600)\n",
    "end=datetime.utcnow() - timedelta(days=5)\n",
    "request = StockBarsRequest(symbol_or_symbols=symbol, start=start, end=end, timeframe=timeframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = client.get_stock_bars(request).df.tz_convert('America/New_York', level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">SPY</th>\n",
       "      <th>2024-02-12 00:00:00-05:00</th>\n",
       "      <td>501.17</td>\n",
       "      <td>503.50</td>\n",
       "      <td>500.240</td>\n",
       "      <td>500.98</td>\n",
       "      <td>56502283.0</td>\n",
       "      <td>437189.0</td>\n",
       "      <td>501.538780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-13 00:00:00-05:00</th>\n",
       "      <td>494.53</td>\n",
       "      <td>497.09</td>\n",
       "      <td>490.715</td>\n",
       "      <td>494.08</td>\n",
       "      <td>113099199.0</td>\n",
       "      <td>779480.0</td>\n",
       "      <td>494.284048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-14 00:00:00-05:00</th>\n",
       "      <td>496.79</td>\n",
       "      <td>499.07</td>\n",
       "      <td>494.400</td>\n",
       "      <td>498.57</td>\n",
       "      <td>68387827.0</td>\n",
       "      <td>536843.0</td>\n",
       "      <td>496.719466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-15 00:00:00-05:00</th>\n",
       "      <td>499.29</td>\n",
       "      <td>502.20</td>\n",
       "      <td>498.795</td>\n",
       "      <td>502.01</td>\n",
       "      <td>61682960.0</td>\n",
       "      <td>516093.0</td>\n",
       "      <td>500.763897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-16 00:00:00-05:00</th>\n",
       "      <td>501.70</td>\n",
       "      <td>502.87</td>\n",
       "      <td>498.750</td>\n",
       "      <td>499.51</td>\n",
       "      <td>75481032.0</td>\n",
       "      <td>531239.0</td>\n",
       "      <td>500.924740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    open    high      low   close  \\\n",
       "symbol timestamp                                                    \n",
       "SPY    2024-02-12 00:00:00-05:00  501.17  503.50  500.240  500.98   \n",
       "       2024-02-13 00:00:00-05:00  494.53  497.09  490.715  494.08   \n",
       "       2024-02-14 00:00:00-05:00  496.79  499.07  494.400  498.57   \n",
       "       2024-02-15 00:00:00-05:00  499.29  502.20  498.795  502.01   \n",
       "       2024-02-16 00:00:00-05:00  501.70  502.87  498.750  499.51   \n",
       "\n",
       "                                       volume  trade_count        vwap  \n",
       "symbol timestamp                                                        \n",
       "SPY    2024-02-12 00:00:00-05:00   56502283.0     437189.0  501.538780  \n",
       "       2024-02-13 00:00:00-05:00  113099199.0     779480.0  494.284048  \n",
       "       2024-02-14 00:00:00-05:00   68387827.0     536843.0  496.719466  \n",
       "       2024-02-15 00:00:00-05:00   61682960.0     516093.0  500.763897  \n",
       "       2024-02-16 00:00:00-05:00   75481032.0     531239.0  500.924740  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(source_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_df = source_df.copy()\n",
    "# pct_change is profit from last close\n",
    "bars_df[\"pct_change\"] = bars_df[\"close\"].pct_change()\n",
    "# signal for when we want to be in or out of a stock\n",
    "#bars_df[\"signal\"] = np.where(bars_df[\"pct_change\"] > 0, 1.0, 0.0)\n",
    "# reaction is the signal diff\n",
    "#bars_df[\"reaction\"] = bars_df[\"signal\"].diff()\n",
    "# action is if we could perfectly predict the next close\n",
    "#bars_df[\"action\"] = bars_df[\"reaction\"].shift(-1)\n",
    "# these values are the high, low, and open as a percentage of the current close\n",
    "bars_df[\"high %\"] = (bars_df[\"high\"] - bars_df[\"close\"])/bars_df[\"close\"]\n",
    "bars_df[\"low %\"] = (bars_df[\"low\"] - bars_df[\"close\"])/bars_df[\"close\"]\n",
    "bars_df[\"open %\"] = (bars_df[\"open\"] - bars_df[\"close\"])/bars_df[\"close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1099 entries, ('SPY', Timestamp('2019-10-07 00:00:00-0400', tz='America/New_York')) to ('SPY', Timestamp('2024-02-16 00:00:00-0500', tz='America/New_York'))\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   open         1099 non-null   float64\n",
      " 1   high         1099 non-null   float64\n",
      " 2   low          1099 non-null   float64\n",
      " 3   close        1099 non-null   float64\n",
      " 4   volume       1099 non-null   float64\n",
      " 5   trade_count  1099 non-null   float64\n",
      " 6   vwap         1099 non-null   float64\n",
      " 7   pct_change   1098 non-null   float64\n",
      " 8   high %       1099 non-null   float64\n",
      " 9   low %        1099 non-null   float64\n",
      " 10  open %       1099 non-null   float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 138.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>high %</th>\n",
       "      <th>low %</th>\n",
       "      <th>open %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">SPY</th>\n",
       "      <th>2019-10-07 00:00:00-04:00</th>\n",
       "      <td>293.47</td>\n",
       "      <td>295.26</td>\n",
       "      <td>292.7700</td>\n",
       "      <td>293.10</td>\n",
       "      <td>62088645.0</td>\n",
       "      <td>314251.0</td>\n",
       "      <td>293.832308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007369</td>\n",
       "      <td>-0.001126</td>\n",
       "      <td>0.001262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-08 00:00:00-04:00</th>\n",
       "      <td>291.04</td>\n",
       "      <td>291.85</td>\n",
       "      <td>288.4900</td>\n",
       "      <td>288.66</td>\n",
       "      <td>103504306.0</td>\n",
       "      <td>495648.0</td>\n",
       "      <td>290.147031</td>\n",
       "      <td>-0.015148</td>\n",
       "      <td>0.011051</td>\n",
       "      <td>-0.000589</td>\n",
       "      <td>0.008245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-09 00:00:00-04:00</th>\n",
       "      <td>290.75</td>\n",
       "      <td>292.30</td>\n",
       "      <td>288.6559</td>\n",
       "      <td>291.12</td>\n",
       "      <td>70229917.0</td>\n",
       "      <td>295519.0</td>\n",
       "      <td>291.056360</td>\n",
       "      <td>0.008522</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>-0.008464</td>\n",
       "      <td>-0.001271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-10 00:00:00-04:00</th>\n",
       "      <td>291.18</td>\n",
       "      <td>294.21</td>\n",
       "      <td>291.0000</td>\n",
       "      <td>293.29</td>\n",
       "      <td>57867131.0</td>\n",
       "      <td>335440.0</td>\n",
       "      <td>292.963831</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>-0.007808</td>\n",
       "      <td>-0.007194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-11 00:00:00-04:00</th>\n",
       "      <td>296.27</td>\n",
       "      <td>298.74</td>\n",
       "      <td>296.1448</td>\n",
       "      <td>296.25</td>\n",
       "      <td>102672621.0</td>\n",
       "      <td>503205.0</td>\n",
       "      <td>297.165136</td>\n",
       "      <td>0.010092</td>\n",
       "      <td>0.008405</td>\n",
       "      <td>-0.000355</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    open    high       low   close  \\\n",
       "symbol timestamp                                                     \n",
       "SPY    2019-10-07 00:00:00-04:00  293.47  295.26  292.7700  293.10   \n",
       "       2019-10-08 00:00:00-04:00  291.04  291.85  288.4900  288.66   \n",
       "       2019-10-09 00:00:00-04:00  290.75  292.30  288.6559  291.12   \n",
       "       2019-10-10 00:00:00-04:00  291.18  294.21  291.0000  293.29   \n",
       "       2019-10-11 00:00:00-04:00  296.27  298.74  296.1448  296.25   \n",
       "\n",
       "                                       volume  trade_count        vwap  \\\n",
       "symbol timestamp                                                         \n",
       "SPY    2019-10-07 00:00:00-04:00   62088645.0     314251.0  293.832308   \n",
       "       2019-10-08 00:00:00-04:00  103504306.0     495648.0  290.147031   \n",
       "       2019-10-09 00:00:00-04:00   70229917.0     295519.0  291.056360   \n",
       "       2019-10-10 00:00:00-04:00   57867131.0     335440.0  292.963831   \n",
       "       2019-10-11 00:00:00-04:00  102672621.0     503205.0  297.165136   \n",
       "\n",
       "                                  pct_change    high %     low %    open %  \n",
       "symbol timestamp                                                            \n",
       "SPY    2019-10-07 00:00:00-04:00         NaN  0.007369 -0.001126  0.001262  \n",
       "       2019-10-08 00:00:00-04:00   -0.015148  0.011051 -0.000589  0.008245  \n",
       "       2019-10-09 00:00:00-04:00    0.008522  0.004053 -0.008464 -0.001271  \n",
       "       2019-10-10 00:00:00-04:00    0.007454  0.003137 -0.007808 -0.007194  \n",
       "       2019-10-11 00:00:00-04:00    0.010092  0.008405 -0.000355  0.000068  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bars_df.info()\n",
    "display(bars_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>high %</th>\n",
       "      <th>low %</th>\n",
       "      <th>open %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-08 00:00:00-04:00</th>\n",
       "      <td>291.04</td>\n",
       "      <td>291.85</td>\n",
       "      <td>288.4900</td>\n",
       "      <td>288.66</td>\n",
       "      <td>103504306.0</td>\n",
       "      <td>495648.0</td>\n",
       "      <td>290.147031</td>\n",
       "      <td>-0.015148</td>\n",
       "      <td>0.011051</td>\n",
       "      <td>-0.000589</td>\n",
       "      <td>0.008245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-09 00:00:00-04:00</th>\n",
       "      <td>290.75</td>\n",
       "      <td>292.30</td>\n",
       "      <td>288.6559</td>\n",
       "      <td>291.12</td>\n",
       "      <td>70229917.0</td>\n",
       "      <td>295519.0</td>\n",
       "      <td>291.056360</td>\n",
       "      <td>0.008522</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>-0.008464</td>\n",
       "      <td>-0.001271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-10 00:00:00-04:00</th>\n",
       "      <td>291.18</td>\n",
       "      <td>294.21</td>\n",
       "      <td>291.0000</td>\n",
       "      <td>293.29</td>\n",
       "      <td>57867131.0</td>\n",
       "      <td>335440.0</td>\n",
       "      <td>292.963831</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>-0.007808</td>\n",
       "      <td>-0.007194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-11 00:00:00-04:00</th>\n",
       "      <td>296.27</td>\n",
       "      <td>298.74</td>\n",
       "      <td>296.1448</td>\n",
       "      <td>296.25</td>\n",
       "      <td>102672621.0</td>\n",
       "      <td>503205.0</td>\n",
       "      <td>297.165136</td>\n",
       "      <td>0.010092</td>\n",
       "      <td>0.008405</td>\n",
       "      <td>-0.000355</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-14 00:00:00-04:00</th>\n",
       "      <td>295.93</td>\n",
       "      <td>296.67</td>\n",
       "      <td>295.5700</td>\n",
       "      <td>296.03</td>\n",
       "      <td>41283428.0</td>\n",
       "      <td>191853.0</td>\n",
       "      <td>296.132073</td>\n",
       "      <td>-0.000743</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>-0.001554</td>\n",
       "      <td>-0.000338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             open    high       low   close       volume  \\\n",
       "timestamp                                                                  \n",
       "2019-10-08 00:00:00-04:00  291.04  291.85  288.4900  288.66  103504306.0   \n",
       "2019-10-09 00:00:00-04:00  290.75  292.30  288.6559  291.12   70229917.0   \n",
       "2019-10-10 00:00:00-04:00  291.18  294.21  291.0000  293.29   57867131.0   \n",
       "2019-10-11 00:00:00-04:00  296.27  298.74  296.1448  296.25  102672621.0   \n",
       "2019-10-14 00:00:00-04:00  295.93  296.67  295.5700  296.03   41283428.0   \n",
       "\n",
       "                           trade_count        vwap  pct_change    high %  \\\n",
       "timestamp                                                                  \n",
       "2019-10-08 00:00:00-04:00     495648.0  290.147031   -0.015148  0.011051   \n",
       "2019-10-09 00:00:00-04:00     295519.0  291.056360    0.008522  0.004053   \n",
       "2019-10-10 00:00:00-04:00     335440.0  292.963831    0.007454  0.003137   \n",
       "2019-10-11 00:00:00-04:00     503205.0  297.165136    0.010092  0.008405   \n",
       "2019-10-14 00:00:00-04:00     191853.0  296.132073   -0.000743  0.002162   \n",
       "\n",
       "                              low %    open %  \n",
       "timestamp                                      \n",
       "2019-10-08 00:00:00-04:00 -0.000589  0.008245  \n",
       "2019-10-09 00:00:00-04:00 -0.008464 -0.001271  \n",
       "2019-10-10 00:00:00-04:00 -0.007808 -0.007194  \n",
       "2019-10-11 00:00:00-04:00 -0.000355  0.000068  \n",
       "2019-10-14 00:00:00-04:00 -0.001554 -0.000338  "
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup DF for model\n",
    "\n",
    "bars_df = bars_df.droplevel(level=0).dropna()\n",
    "bars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data set\n",
    "\n",
    "scaler = StandardScaler()\n",
    "bars_df_scaled = scaler.fit_transform(bars_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "\n",
    "# input shape\n",
    "\n",
    "input_shape = bars_df_scaled.shape[1]\n",
    "latent_dim = 11\n",
    "num_samples = bars_df_scaled.shape[0]\n",
    "batch_size = 32\n",
    "\n",
    "# Generate Random Walk noise\n",
    "\n",
    "gaussian_noise = np.random.normal(0,1,size=(batch_size,input_shape))\n",
    "random_walk_noise = np.cumsum(gaussian_noise, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator\n",
    "\n",
    "build_generator = Sequential([\n",
    "    Dense(128,input_shape=(input_shape,), activation=\"relu\"),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dense(512, activation=\"relu\"),\n",
    "    Dense(input_shape, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Define descriminator\n",
    "\n",
    "build_discriminator = Sequential([\n",
    "    Dense(512, input_shape=(input_shape,), activation=\"relu\"),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile generator\n",
    "build_generator.compile(loss = \"mse\", optimizer=\"adam\")\n",
    "\n",
    "# Compile discriminator\n",
    "build_discriminator.compile(loss=\"mse\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine models\n",
    "\n",
    "z = tf.keras.Input(shape=(latent_dim,))\n",
    "img = build_generator(z)\n",
    "validity = build_discriminator(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 11)]              0         \n",
      "                                                                 \n",
      " sequential_28 (Sequential)  (None, 11)                171787    \n",
      "                                                                 \n",
      " sequential_29 (Sequential)  (None, 1)                 170497    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 342284 (1.31 MB)\n",
      "Trainable params: 342284 (1.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define combined models\n",
    "\n",
    "combined = tf.keras.Model(z, validity)\n",
    "combined.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Print summary of the combined model\n",
    "combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 21:17:06.288310: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-02-22 21:17:06.407740: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-02-22 21:17:06.715402: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Discriminator Loss: 0.2896665781736374, Generator Loss: [0.27671611309051514, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 1, Discriminator Loss: 0.2755270153284073, Generator Loss: [0.2998466193675995, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 2, Discriminator Loss: 0.23933595418930054, Generator Loss: [0.3625606298446655, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 3, Discriminator Loss: 0.2234175130724907, Generator Loss: [0.38688230514526367, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 4, Discriminator Loss: 0.2323327660560608, Generator Loss: [0.36080676317214966, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 5, Discriminator Loss: 0.2204822674393654, Generator Loss: [0.36482325196266174, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 6, Discriminator Loss: 0.2035106122493744, Generator Loss: [0.41634005308151245, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 7, Discriminator Loss: 0.17774561047554016, Generator Loss: [0.4851454496383667, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 8, Discriminator Loss: 0.1500350683927536, Generator Loss: [0.5537911057472229, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 9, Discriminator Loss: 0.15602560341358185, Generator Loss: [0.5375537872314453, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 10, Discriminator Loss: 0.15678931772708893, Generator Loss: [0.538698673248291, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 11, Discriminator Loss: 0.14833416789770126, Generator Loss: [0.6331175565719604, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 12, Discriminator Loss: 0.11942523717880249, Generator Loss: [0.6526932120323181, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 13, Discriminator Loss: 0.10432697460055351, Generator Loss: [0.6601983308792114, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 14, Discriminator Loss: 0.11327477544546127, Generator Loss: [0.6368557214736938, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 15, Discriminator Loss: 0.11351630836725235, Generator Loss: [0.6785388588905334, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 16, Discriminator Loss: 0.09058322384953499, Generator Loss: [0.7989668846130371, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 17, Discriminator Loss: 0.10428903251886368, Generator Loss: [0.8035565614700317, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 18, Discriminator Loss: 0.0986986979842186, Generator Loss: [0.7246251106262207, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 19, Discriminator Loss: 0.10338273644447327, Generator Loss: [0.8609581589698792, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 20, Discriminator Loss: 0.07296963408589363, Generator Loss: [0.9110230207443237, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 21, Discriminator Loss: 0.1273387372493744, Generator Loss: [0.5847005844116211, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 22, Discriminator Loss: 0.3094062805175781, Generator Loss: [0.28332120180130005, 0.46875]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 23, Discriminator Loss: 0.3596280664205551, Generator Loss: [0.04703156650066376, 0.96875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 24, Discriminator Loss: 0.3522579222917557, Generator Loss: [0.006976501550525427, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 25, Discriminator Loss: 0.391683429479599, Generator Loss: [0.000331681570969522, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 26, Discriminator Loss: 0.4249452203512192, Generator Loss: [5.1836250349879265e-05, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 27, Discriminator Loss: 0.45825065672397614, Generator Loss: [5.8110299505642615e-06, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 28, Discriminator Loss: 0.3836192488670349, Generator Loss: [6.249956186366035e-06, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 29, Discriminator Loss: 0.44295382499694824, Generator Loss: [3.5165044209861662e-06, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 30, Discriminator Loss: 0.40832625329494476, Generator Loss: [9.116813453147188e-05, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 31, Discriminator Loss: 0.3915182054042816, Generator Loss: [0.001721788663417101, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 32, Discriminator Loss: 0.3477501720190048, Generator Loss: [0.04319500923156738, 0.9375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 33, Discriminator Loss: 0.30483385920524597, Generator Loss: [0.10045049339532852, 0.875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 34, Discriminator Loss: 0.2774656191468239, Generator Loss: [0.3729245364665985, 0.375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 35, Discriminator Loss: 0.2700718194246292, Generator Loss: [0.8310902118682861, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 36, Discriminator Loss: 0.2390597127377987, Generator Loss: [0.9718914031982422, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 37, Discriminator Loss: 0.159217458407511, Generator Loss: [0.9997915625572205, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 38, Discriminator Loss: 0.12380074981628653, Generator Loss: [0.9999963641166687, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 39, Discriminator Loss: 0.26607659276987583, Generator Loss: [0.9999935626983643, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 40, Discriminator Loss: 0.23242856695467395, Generator Loss: [0.9999974966049194, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 41, Discriminator Loss: 0.3139712033458508, Generator Loss: [0.9999948740005493, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 42, Discriminator Loss: 0.2791412584732669, Generator Loss: [0.9999920129776001, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 43, Discriminator Loss: 0.14593273002864393, Generator Loss: [0.999846339225769, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 44, Discriminator Loss: 0.16004165985214058, Generator Loss: [0.9856561422348022, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 45, Discriminator Loss: 0.27892423421144485, Generator Loss: [0.7866780757904053, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 46, Discriminator Loss: 0.32026851177215576, Generator Loss: [0.7868754863739014, 0.15625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 47, Discriminator Loss: 0.3874017596244812, Generator Loss: [0.9971491098403931, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 48, Discriminator Loss: 0.11223569960566238, Generator Loss: [0.9998703002929688, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 49, Discriminator Loss: 0.1670483757970942, Generator Loss: [0.9999762177467346, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 50, Discriminator Loss: 0.16873358618977363, Generator Loss: [0.999927282333374, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 51, Discriminator Loss: 0.15341008466202766, Generator Loss: [0.9679607152938843, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 52, Discriminator Loss: 0.22995982319116592, Generator Loss: [0.6340605020523071, 0.34375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 53, Discriminator Loss: 0.33459267020225525, Generator Loss: [0.5569494962692261, 0.46875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 54, Discriminator Loss: 0.3535013347864151, Generator Loss: [0.5066165924072266, 0.40625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 55, Discriminator Loss: 0.3280688226222992, Generator Loss: [0.4139586091041565, 0.59375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 56, Discriminator Loss: 0.3433232307434082, Generator Loss: [0.5123820304870605, 0.46875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 57, Discriminator Loss: 0.3619236797094345, Generator Loss: [0.3762643039226532, 0.625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 58, Discriminator Loss: 0.3862554430961609, Generator Loss: [0.3120296001434326, 0.6875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 59, Discriminator Loss: 0.35332833230495453, Generator Loss: [0.33852916955947876, 0.65625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 60, Discriminator Loss: 0.34922051429748535, Generator Loss: [0.3501408100128174, 0.65625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 61, Discriminator Loss: 0.4230107367038727, Generator Loss: [0.5614256858825684, 0.4375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 62, Discriminator Loss: 0.42112286388874054, Generator Loss: [0.37464815378189087, 0.625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 63, Discriminator Loss: 0.45561596751213074, Generator Loss: [0.34376007318496704, 0.65625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 64, Discriminator Loss: 0.2966366410255432, Generator Loss: [0.3437499403953552, 0.65625]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 65, Discriminator Loss: 0.4048750102519989, Generator Loss: [0.32487356662750244, 0.65625]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 66, Discriminator Loss: 0.3777189999818802, Generator Loss: [0.375, 0.625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 67, Discriminator Loss: 0.42652952671051025, Generator Loss: [0.34374770522117615, 0.65625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 68, Discriminator Loss: 0.39020295441150665, Generator Loss: [0.28125, 0.71875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 69, Discriminator Loss: 0.3977755904197693, Generator Loss: [0.2487057000398636, 0.75]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 70, Discriminator Loss: 0.3660760819911957, Generator Loss: [0.375000923871994, 0.625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 71, Discriminator Loss: 0.40777552127838135, Generator Loss: [0.43750351667404175, 0.5625]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 72, Discriminator Loss: 0.3746579438447952, Generator Loss: [0.4062490165233612, 0.59375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 73, Discriminator Loss: 0.3042481243610382, Generator Loss: [0.3158070743083954, 0.6875]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 74, Discriminator Loss: 0.3486267626285553, Generator Loss: [0.15628588199615479, 0.84375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 75, Discriminator Loss: 0.42265766859054565, Generator Loss: [0.49286913871765137, 0.5]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 76, Discriminator Loss: 0.4317355751991272, Generator Loss: [0.2545147240161896, 0.75]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 77, Discriminator Loss: 0.3281967043876648, Generator Loss: [0.37490028142929077, 0.625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 78, Discriminator Loss: 0.3437604010105133, Generator Loss: [0.25004082918167114, 0.75]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 79, Discriminator Loss: 0.3098013699054718, Generator Loss: [0.3128194212913513, 0.6875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 80, Discriminator Loss: 0.35873807966709137, Generator Loss: [0.34370386600494385, 0.65625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 81, Discriminator Loss: 0.3794700354337692, Generator Loss: [0.25362446904182434, 0.71875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 82, Discriminator Loss: 0.34112969040870667, Generator Loss: [0.24967284500598907, 0.75]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 83, Discriminator Loss: 0.37092964351177216, Generator Loss: [0.2499999850988388, 0.75]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 84, Discriminator Loss: 0.333352267742157, Generator Loss: [0.33816826343536377, 0.65625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 85, Discriminator Loss: 0.2923765704035759, Generator Loss: [0.34318381547927856, 0.65625]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 86, Discriminator Loss: 0.3147503733634949, Generator Loss: [0.43108922243118286, 0.5625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 87, Discriminator Loss: 0.1392065260988602, Generator Loss: [0.9999971985816956, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 88, Discriminator Loss: 0.17700189359179927, Generator Loss: [0.999970555305481, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 89, Discriminator Loss: 0.22683993461396312, Generator Loss: [0.9927652478218079, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 90, Discriminator Loss: 0.37936821579933167, Generator Loss: [0.9687562584877014, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 91, Discriminator Loss: 0.4727460443973541, Generator Loss: [0.9375744462013245, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 92, Discriminator Loss: 0.35761912167072296, Generator Loss: [0.9687656164169312, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 93, Discriminator Loss: 0.4138599932193756, Generator Loss: [0.9703080058097839, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 94, Discriminator Loss: 0.38985587656497955, Generator Loss: [0.9984449744224548, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 95, Discriminator Loss: 0.23441007501350697, Generator Loss: [0.9999993443489075, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 96, Discriminator Loss: 0.2043857723477897, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 97, Discriminator Loss: 0.265839159488678, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 98, Discriminator Loss: 0.29686975479125977, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 99, Discriminator Loss: 0.3125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 100, Discriminator Loss: 0.20312485098838806, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 101, Discriminator Loss: 0.21788457036018372, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 102, Discriminator Loss: 0.2962365746498108, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 103, Discriminator Loss: 0.2651907205581665, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 104, Discriminator Loss: 0.2802792191505432, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 105, Discriminator Loss: 0.2733387351036072, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 106, Discriminator Loss: 0.2952011823654175, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 107, Discriminator Loss: 0.3045697510242462, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 108, Discriminator Loss: 0.2029975950717926, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 109, Discriminator Loss: 0.2362012267112732, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 110, Discriminator Loss: 0.20689590275287628, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 111, Discriminator Loss: 0.221370130777359, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 112, Discriminator Loss: 0.2585923671722412, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 113, Discriminator Loss: 0.31247207522392273, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 114, Discriminator Loss: 0.21166500449180603, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 115, Discriminator Loss: 0.109375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 116, Discriminator Loss: 0.2475496530532837, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 117, Discriminator Loss: 0.20158980786800385, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 118, Discriminator Loss: 0.2822006046772003, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 119, Discriminator Loss: 0.25173318386089555, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 120, Discriminator Loss: 0.23217927845894337, Generator Loss: [0.9842650890350342, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 121, Discriminator Loss: 0.250436432659626, Generator Loss: [0.32606688141822815, 0.65625]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 122, Discriminator Loss: 0.1811090037226677, Generator Loss: [0.3382401168346405, 0.65625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 123, Discriminator Loss: 0.32785215973854065, Generator Loss: [0.3477374315261841, 0.625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 124, Discriminator Loss: 0.3003808706998825, Generator Loss: [0.4217483699321747, 0.5625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 125, Discriminator Loss: 0.38500383496284485, Generator Loss: [0.6523489952087402, 0.3125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 126, Discriminator Loss: 0.36359868943691254, Generator Loss: [0.4857148826122284, 0.46875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 127, Discriminator Loss: 0.39061999320983887, Generator Loss: [0.13802805542945862, 0.84375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 128, Discriminator Loss: 0.29699569940567017, Generator Loss: [0.2500092387199402, 0.75]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 129, Discriminator Loss: 0.3443131446838379, Generator Loss: [0.22864145040512085, 0.75]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 130, Discriminator Loss: 0.4062526673078537, Generator Loss: [0.21875, 0.78125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 131, Discriminator Loss: 0.561849057674408, Generator Loss: [0.23313948512077332, 0.75]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 132, Discriminator Loss: 0.6093700230121613, Generator Loss: [0.12499906867742538, 0.875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 133, Discriminator Loss: 0.6115051507949829, Generator Loss: [0.0445186048746109, 0.9375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 134, Discriminator Loss: 0.579425185918808, Generator Loss: [0.0625, 0.9375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 135, Discriminator Loss: 0.5064215064048767, Generator Loss: [0.1461193859577179, 0.84375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 136, Discriminator Loss: 0.4843730926513672, Generator Loss: [0.03125, 0.96875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 137, Discriminator Loss: 0.546875, Generator Loss: [1.9584334154387761e-13, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 138, Discriminator Loss: 0.5625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 139, Discriminator Loss: 0.5468749105930328, Generator Loss: [0.031133636832237244, 0.96875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 140, Discriminator Loss: 0.5468690395355225, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 141, Discriminator Loss: 0.5936939716339111, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 142, Discriminator Loss: 0.5738440603017807, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 143, Discriminator Loss: 0.6023070812225342, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 144, Discriminator Loss: 0.554922878742218, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 145, Discriminator Loss: 0.4469364434480667, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 146, Discriminator Loss: 0.46799489855766296, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 147, Discriminator Loss: 0.5482157170772552, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 148, Discriminator Loss: 0.4178627133369446, Generator Loss: [3.0020430585864233e-13, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 149, Discriminator Loss: 0.453125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 150, Discriminator Loss: 0.46875372529029846, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 151, Discriminator Loss: 0.53125, Generator Loss: [0.03125, 0.96875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 152, Discriminator Loss: 0.4843766689300537, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 153, Discriminator Loss: 0.4844006299972534, Generator Loss: [3.071720655611898e-11, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 154, Discriminator Loss: 0.5287375450134277, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 155, Discriminator Loss: 0.4843749552965164, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 156, Discriminator Loss: 0.4843749403953552, Generator Loss: [1.011618337543041e-06, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 157, Discriminator Loss: 0.5156248509883881, Generator Loss: [0.030863607302308083, 0.96875]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 158, Discriminator Loss: 0.48184457421302795, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 159, Discriminator Loss: 0.5468744933605194, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 160, Discriminator Loss: 0.45312443375587463, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 161, Discriminator Loss: 0.4372675269842148, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 162, Discriminator Loss: 0.46852704882621765, Generator Loss: [7.105427357601002e-15, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 163, Discriminator Loss: 0.4374992400407791, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 164, Discriminator Loss: 0.5312487483024597, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 165, Discriminator Loss: 0.5108450353145599, Generator Loss: [2.4336075057362905e-06, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 166, Discriminator Loss: 0.42187264561653137, Generator Loss: [0.0625, 0.9375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 167, Discriminator Loss: 0.4843461960554123, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 168, Discriminator Loss: 0.45309288799762726, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 169, Discriminator Loss: 0.4999879151582718, Generator Loss: [4.440892098500626e-16, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 170, Discriminator Loss: 0.4374839961528778, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 171, Discriminator Loss: 0.4360092580318451, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 172, Discriminator Loss: 0.4843345284461975, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 173, Discriminator Loss: 0.4822865426540375, Generator Loss: [0.031245596706867218, 0.96875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 174, Discriminator Loss: 0.46661657094955444, Generator Loss: [0.001424378831870854, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 175, Discriminator Loss: 0.48156413435935974, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 176, Discriminator Loss: 0.4062499403953552, Generator Loss: [0.09356199204921722, 0.90625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 177, Discriminator Loss: 0.42185837030410767, Generator Loss: [6.156723202366265e-07, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 178, Discriminator Loss: 0.39057157933712006, Generator Loss: [0.03125, 0.96875]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 179, Discriminator Loss: 0.4209669530391693, Generator Loss: [0.06316350400447845, 0.9375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 180, Discriminator Loss: 0.35444217920303345, Generator Loss: [0.07384710013866425, 0.90625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 181, Discriminator Loss: 0.3245576322078705, Generator Loss: [0.03125, 0.96875]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 182, Discriminator Loss: 0.35724034160375595, Generator Loss: [0.09375, 0.90625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 183, Discriminator Loss: 0.35984914004802704, Generator Loss: [0.03097362443804741, 0.96875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 184, Discriminator Loss: 0.33592014014720917, Generator Loss: [0.09375, 0.90625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 185, Discriminator Loss: 0.24998918175697327, Generator Loss: [0.08519172668457031, 0.90625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 186, Discriminator Loss: 0.32612258195877075, Generator Loss: [0.09108784794807434, 0.90625]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 187, Discriminator Loss: 0.2824193984270096, Generator Loss: [0.04935121908783913, 0.9375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 188, Discriminator Loss: 0.29884132742881775, Generator Loss: [0.12472166121006012, 0.84375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 189, Discriminator Loss: 0.31780701875686646, Generator Loss: [0.10539042949676514, 0.875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 190, Discriminator Loss: 0.21871232986450195, Generator Loss: [0.03179892897605896, 0.96875]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 191, Discriminator Loss: 0.3002549707889557, Generator Loss: [0.03810419514775276, 0.96875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 192, Discriminator Loss: 0.19594742357730865, Generator Loss: [0.032060977071523666, 0.96875]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 193, Discriminator Loss: 0.33300934731960297, Generator Loss: [0.03125043958425522, 0.96875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 194, Discriminator Loss: 0.2785705700516701, Generator Loss: [0.032135847955942154, 0.96875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 195, Discriminator Loss: 0.3466687798500061, Generator Loss: [0.062086980789899826, 0.9375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 196, Discriminator Loss: 0.25350434333086014, Generator Loss: [0.17061294615268707, 0.8125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 197, Discriminator Loss: 0.23516795784235, Generator Loss: [0.1678171455860138, 0.8125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 198, Discriminator Loss: 0.24747339822351933, Generator Loss: [0.5140102505683899, 0.46875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 199, Discriminator Loss: 0.15625018067657948, Generator Loss: [0.6485244035720825, 0.3125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 200, Discriminator Loss: 0.1874968707561493, Generator Loss: [0.7910113334655762, 0.1875]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 201, Discriminator Loss: 0.1489444635808468, Generator Loss: [0.9643886685371399, 0.03125]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 202, Discriminator Loss: 0.19057436287403107, Generator Loss: [0.7965477705001831, 0.1875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 203, Discriminator Loss: 0.20177411288022995, Generator Loss: [0.5652509331703186, 0.4375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 204, Discriminator Loss: 0.17152442783117294, Generator Loss: [0.3470509648323059, 0.65625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 205, Discriminator Loss: 0.34335145354270935, Generator Loss: [0.24231365323066711, 0.75]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 206, Discriminator Loss: 0.37390628457069397, Generator Loss: [0.06250613927841187, 0.9375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 207, Discriminator Loss: 0.2641333341598511, Generator Loss: [1.1102230246251565e-14, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 208, Discriminator Loss: 0.3681183010339737, Generator Loss: [0.060661472380161285, 0.9375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 209, Discriminator Loss: 0.26561667025089264, Generator Loss: [0.4646627902984619, 0.5]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 210, Discriminator Loss: 0.22646236419677734, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 211, Discriminator Loss: 0.20313547826646583, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 212, Discriminator Loss: 0.21870014071464539, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 213, Discriminator Loss: 0.29687607288360596, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 214, Discriminator Loss: 0.26561951637268066, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 215, Discriminator Loss: 0.14062155783176422, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 216, Discriminator Loss: 0.2968748211860657, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 217, Discriminator Loss: 0.265625, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 218, Discriminator Loss: 0.29691362380981445, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 219, Discriminator Loss: 0.218753844499588, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 220, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 221, Discriminator Loss: 0.265625, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 222, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 223, Discriminator Loss: 0.2968764901161194, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 224, Discriminator Loss: 0.26562467217445374, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 225, Discriminator Loss: 0.310397207736969, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 226, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 227, Discriminator Loss: 0.2042672485113144, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 228, Discriminator Loss: 0.1875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 229, Discriminator Loss: 0.15625, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 230, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 231, Discriminator Loss: 0.24537622928619385, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 232, Discriminator Loss: 0.2499987632036209, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 233, Discriminator Loss: 0.21862846612930298, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 234, Discriminator Loss: 0.34375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 235, Discriminator Loss: 0.24999995529651642, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 236, Discriminator Loss: 0.21868667006492615, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 237, Discriminator Loss: 0.265625, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 238, Discriminator Loss: 0.28124895691871643, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 239, Discriminator Loss: 0.265625, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 240, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 241, Discriminator Loss: 0.26560476422309875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 242, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 243, Discriminator Loss: 0.23440226912498474, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 244, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 245, Discriminator Loss: 0.359375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 246, Discriminator Loss: 0.265625, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 247, Discriminator Loss: 0.2637695074081421, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 248, Discriminator Loss: 0.23443952202796936, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 249, Discriminator Loss: 0.2343750298023224, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 250, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 251, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 252, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 253, Discriminator Loss: 0.2757341265678406, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 254, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 255, Discriminator Loss: 0.3593749403953552, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 256, Discriminator Loss: 0.24805358052253723, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 257, Discriminator Loss: 0.171875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 258, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 259, Discriminator Loss: 0.203125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 260, Discriminator Loss: 0.3125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 261, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 262, Discriminator Loss: 0.22050312161445618, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 263, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 264, Discriminator Loss: 0.26563525199890137, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 265, Discriminator Loss: 0.22127002477645874, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 266, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 267, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 268, Discriminator Loss: 0.28123974800109863, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 269, Discriminator Loss: 0.35971540212631226, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 270, Discriminator Loss: 0.20312176644802094, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 271, Discriminator Loss: 0.29703083634376526, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 272, Discriminator Loss: 0.1562986969947815, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 273, Discriminator Loss: 0.265625, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 274, Discriminator Loss: 0.265625, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 275, Discriminator Loss: 0.19803380966186523, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 276, Discriminator Loss: 0.203125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 277, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 278, Discriminator Loss: 0.1942412108182907, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 279, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 280, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 281, Discriminator Loss: 0.26559576392173767, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 282, Discriminator Loss: 0.26811903715133667, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 283, Discriminator Loss: 0.2187485247850418, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 284, Discriminator Loss: 0.2499999701976776, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 285, Discriminator Loss: 0.25530004501342773, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 286, Discriminator Loss: 0.23437467217445374, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 287, Discriminator Loss: 0.15619495511054993, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 288, Discriminator Loss: 0.3465299606323242, Generator Loss: [0.40625, 0.59375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 289, Discriminator Loss: 0.34186945855617523, Generator Loss: [0.2376806139945984, 0.75]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 290, Discriminator Loss: 0.2767854928970337, Generator Loss: [0.02942570298910141, 0.96875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 291, Discriminator Loss: 0.6406244039535522, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 292, Discriminator Loss: 0.749224990606308, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 293, Discriminator Loss: 0.6874999701976776, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 294, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 295, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 296, Discriminator Loss: 0.640625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 297, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 298, Discriminator Loss: 0.7187499701976776, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 299, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 300, Discriminator Loss: 0.7968749701976776, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 301, Discriminator Loss: 0.6744044125080109, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 302, Discriminator Loss: 0.65625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 303, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 304, Discriminator Loss: 0.7187497913837433, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 305, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 306, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 307, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 308, Discriminator Loss: 0.71875, Generator Loss: [9.17356155696325e-05, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 309, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 310, Discriminator Loss: 0.78125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 311, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 312, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 313, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 314, Discriminator Loss: 0.7607476115226746, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 315, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 316, Discriminator Loss: 0.796875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 317, Discriminator Loss: 0.7343716323375702, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 318, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 319, Discriminator Loss: 0.7031187415122986, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 320, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 321, Discriminator Loss: 0.6874996423721313, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 322, Discriminator Loss: 0.65625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 323, Discriminator Loss: 0.7187401950359344, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 324, Discriminator Loss: 0.703125461935997, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 325, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 326, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 327, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 328, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 329, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 330, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 331, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 332, Discriminator Loss: 0.71875, Generator Loss: [0.031248290091753006, 0.96875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 333, Discriminator Loss: 0.640625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 334, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 335, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 336, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 337, Discriminator Loss: 0.637971043586731, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 338, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 339, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 340, Discriminator Loss: 0.7343704104423523, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 341, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 342, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 343, Discriminator Loss: 0.78125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 344, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 345, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 346, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 347, Discriminator Loss: 0.65625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 348, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 349, Discriminator Loss: 0.796875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 350, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 351, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 352, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 353, Discriminator Loss: 0.640625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 354, Discriminator Loss: 0.6401196420192719, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 355, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 356, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 357, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 358, Discriminator Loss: 0.78125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 359, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 360, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 361, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 362, Discriminator Loss: 0.78125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 363, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 364, Discriminator Loss: 0.7810941934585571, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 365, Discriminator Loss: 0.625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 366, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 367, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 368, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 369, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 370, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 371, Discriminator Loss: 0.65625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 372, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 373, Discriminator Loss: 0.78125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 374, Discriminator Loss: 0.72230663895607, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 375, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 376, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 377, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 378, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 379, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 380, Discriminator Loss: 0.7806140780448914, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 381, Discriminator Loss: 0.7343735992908478, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 382, Discriminator Loss: 0.7501862645149231, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 383, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 384, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 385, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 386, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 387, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 388, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 389, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 390, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 391, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 392, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 393, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 394, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 395, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 396, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 397, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 398, Discriminator Loss: 0.6874743103981018, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 399, Discriminator Loss: 0.78125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 400, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 401, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 402, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 403, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 404, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 405, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 406, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 407, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 408, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 409, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 410, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 411, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 412, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 413, Discriminator Loss: 0.65625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 414, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 415, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 416, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 417, Discriminator Loss: 0.796875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 418, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 419, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 420, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 421, Discriminator Loss: 0.6562432646751404, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 422, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 423, Discriminator Loss: 0.7344002276659012, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 424, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 425, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 426, Discriminator Loss: 0.640625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 427, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 428, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 429, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 430, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 431, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 432, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 433, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 434, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 435, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 436, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 437, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 438, Discriminator Loss: 0.7675266861915588, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 439, Discriminator Loss: 0.625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 440, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 441, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 442, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 443, Discriminator Loss: 0.78125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoch 444, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 445, Discriminator Loss: 0.7146094441413879, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 446, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 447, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 448, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 449, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 450, Discriminator Loss: 0.640625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 451, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 452, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 453, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 454, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoch 455, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 456, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 457, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 458, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 459, Discriminator Loss: 0.7363056838512421, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 460, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 461, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 462, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 463, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 464, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 465, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 466, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 467, Discriminator Loss: 0.7189682424068451, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 468, Discriminator Loss: 0.8125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 469, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 470, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 471, Discriminator Loss: 0.65625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 472, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 473, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 474, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 475, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 476, Discriminator Loss: 0.6718897819519043, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 477, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 478, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 479, Discriminator Loss: 0.65625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 480, Discriminator Loss: 0.7610161602497101, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 481, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 482, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 483, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 484, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 485, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 486, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 487, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 488, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 489, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 490, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 491, Discriminator Loss: 0.65625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 492, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 493, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 494, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 495, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 496, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 497, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 498, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 499, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 500, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 501, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 502, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 503, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 504, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 505, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 506, Discriminator Loss: 0.7343584299087524, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 507, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 508, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 509, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 510, Discriminator Loss: 0.65625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 511, Discriminator Loss: 0.640625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 512, Discriminator Loss: 0.7812501490116119, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 513, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 514, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 515, Discriminator Loss: 0.609375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 516, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 517, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 518, Discriminator Loss: 0.7054422795772552, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 519, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 520, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 521, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 522, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 523, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 524, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 525, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 526, Discriminator Loss: 0.7342322170734406, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 527, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 528, Discriminator Loss: 0.65625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 529, Discriminator Loss: 0.7187463939189911, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 530, Discriminator Loss: 0.65625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 531, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 532, Discriminator Loss: 0.7338020205497742, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 533, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 534, Discriminator Loss: 0.828125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 535, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 536, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 537, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 538, Discriminator Loss: 0.7636367082595825, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 539, Discriminator Loss: 0.7031257450580597, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 540, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 541, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 542, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 543, Discriminator Loss: 0.7269935607910156, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 544, Discriminator Loss: 0.6718750596046448, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 545, Discriminator Loss: 0.65625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 546, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 547, Discriminator Loss: 0.65625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 548, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 549, Discriminator Loss: 0.7187499850988388, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 550, Discriminator Loss: 0.6718717366456985, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 551, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 552, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 553, Discriminator Loss: 0.6985699087381363, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 554, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 555, Discriminator Loss: 0.6245793253183365, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 556, Discriminator Loss: 0.640625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 557, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 558, Discriminator Loss: 0.7343740314245224, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 559, Discriminator Loss: 0.6877976059913635, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 560, Discriminator Loss: 0.65625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 561, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 562, Discriminator Loss: 0.6718408763408661, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 563, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 564, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 565, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 566, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 567, Discriminator Loss: 0.78125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 568, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 569, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 570, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 571, Discriminator Loss: 0.8125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 572, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 573, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 574, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 575, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 576, Discriminator Loss: 0.7499997615814209, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 577, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 578, Discriminator Loss: 0.7031250447034836, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 579, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 580, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 581, Discriminator Loss: 0.78125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 582, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 583, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 584, Discriminator Loss: 0.765625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 585, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 586, Discriminator Loss: 0.7121231406927109, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 587, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 588, Discriminator Loss: 0.7656194567680359, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 589, Discriminator Loss: 0.6562492847442627, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 590, Discriminator Loss: 0.7031148970127106, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 591, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 592, Discriminator Loss: 0.75, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 593, Discriminator Loss: 0.6700113415718079, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 594, Discriminator Loss: 0.779373824596405, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 595, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 596, Discriminator Loss: 0.71875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 597, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 598, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 599, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 600, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 601, Discriminator Loss: 0.8125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 602, Discriminator Loss: 0.78125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 603, Discriminator Loss: 0.7343724817037582, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 604, Discriminator Loss: 0.7332628965377808, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 605, Discriminator Loss: 0.734375, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 606, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 607, Discriminator Loss: 0.709710568189621, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 608, Discriminator Loss: 0.6406218111515045, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 609, Discriminator Loss: 0.6708652675151825, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 610, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 611, Discriminator Loss: 0.6874960213899612, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 612, Discriminator Loss: 0.625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 613, Discriminator Loss: 0.78125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 614, Discriminator Loss: 0.7701456844806671, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 615, Discriminator Loss: 0.671875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 616, Discriminator Loss: 0.703125, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 617, Discriminator Loss: 0.7031217515468597, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 618, Discriminator Loss: 0.6875, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 619, Discriminator Loss: 0.640625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 620, Discriminator Loss: 0.65625, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 621, Discriminator Loss: 0.6874974370002747, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 622, Discriminator Loss: 0.7187241315841675, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 623, Discriminator Loss: 0.6767479479312897, Generator Loss: [0.0, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 624, Discriminator Loss: 0.49442848563194275, Generator Loss: [0.8025854825973511, 0.1875]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 625, Discriminator Loss: 0.12501803785562515, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 626, Discriminator Loss: 0.21874659337521507, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 627, Discriminator Loss: 0.2968749701976776, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 628, Discriminator Loss: 0.2500063180923462, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 629, Discriminator Loss: 0.23526892066001892, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 630, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 631, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 632, Discriminator Loss: 0.3125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 633, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 634, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 635, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 636, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoch 637, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 638, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 639, Discriminator Loss: 0.2651512622833252, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 640, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 641, Discriminator Loss: 0.24999986588954926, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 642, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 643, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 644, Discriminator Loss: 0.171875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 645, Discriminator Loss: 0.203125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 646, Discriminator Loss: 0.3124997615814209, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 647, Discriminator Loss: 0.3125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 648, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 649, Discriminator Loss: 0.24999988079071045, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 650, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 651, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 652, Discriminator Loss: 0.23436221480369568, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 653, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 654, Discriminator Loss: 0.265625, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 655, Discriminator Loss: 0.23436614871025085, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 656, Discriminator Loss: 0.1896083950996399, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 657, Discriminator Loss: 0.203125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 658, Discriminator Loss: 0.203125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 659, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 660, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 661, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 662, Discriminator Loss: 0.1528785228729248, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 663, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 664, Discriminator Loss: 0.2498471438884735, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 665, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 666, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 667, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 668, Discriminator Loss: 0.21870192885398865, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 669, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 670, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 671, Discriminator Loss: 0.265625, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 672, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 673, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 674, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 675, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 676, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 677, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 678, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 679, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 680, Discriminator Loss: 0.265625, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 681, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 682, Discriminator Loss: 0.3125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 683, Discriminator Loss: 0.171875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 684, Discriminator Loss: 0.3118976950645447, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch 685, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 686, Discriminator Loss: 0.21781250834465027, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 687, Discriminator Loss: 0.21874985098838806, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 688, Discriminator Loss: 0.26562488079071045, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 689, Discriminator Loss: 0.1875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 690, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 691, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 692, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 693, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 694, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 695, Discriminator Loss: 0.26542046666145325, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 696, Discriminator Loss: 0.3125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 697, Discriminator Loss: 0.203125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 698, Discriminator Loss: 0.328125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 699, Discriminator Loss: 0.171875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 700, Discriminator Loss: 0.26555538177490234, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 701, Discriminator Loss: 0.29671433568000793, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 702, Discriminator Loss: 0.3125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 703, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 704, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 705, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 706, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 707, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 708, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 709, Discriminator Loss: 0.26107314229011536, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 710, Discriminator Loss: 0.203125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 711, Discriminator Loss: 0.2812499701976776, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 712, Discriminator Loss: 0.328125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 713, Discriminator Loss: 0.203125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 714, Discriminator Loss: 0.1875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoch 715, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 716, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 717, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoch 718, Discriminator Loss: 0.2816998362541199, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 719, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 720, Discriminator Loss: 0.265625, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 721, Discriminator Loss: 0.2343985140323639, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 722, Discriminator Loss: 0.18750005960464478, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 723, Discriminator Loss: 0.20313063263893127, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 724, Discriminator Loss: 0.359375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 725, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 726, Discriminator Loss: 0.2324875444173813, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 727, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 728, Discriminator Loss: 0.23437906801700592, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 729, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 730, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 731, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 732, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 733, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 734, Discriminator Loss: 0.23439523577690125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 735, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 736, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 737, Discriminator Loss: 0.33187341690063477, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 738, Discriminator Loss: 0.15907758474349976, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 739, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 740, Discriminator Loss: 0.1875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 741, Discriminator Loss: 0.23437510430812836, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 742, Discriminator Loss: 0.265625, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 743, Discriminator Loss: 0.24624240398406982, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 744, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 745, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 746, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 747, Discriminator Loss: 0.25, Generator Loss: [0.9687501192092896, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 748, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 749, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 750, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 751, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 752, Discriminator Loss: 0.34375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 753, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 754, Discriminator Loss: 0.23438149690628052, Generator Loss: [0.9999999403953552, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 755, Discriminator Loss: 0.1875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 756, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 757, Discriminator Loss: 0.1875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 758, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 759, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 760, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 761, Discriminator Loss: 0.140625, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 762, Discriminator Loss: 0.15625, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 763, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 764, Discriminator Loss: 0.3125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 765, Discriminator Loss: 0.234375, Generator Loss: [0.9720704555511475, 0.03125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 766, Discriminator Loss: 0.21875423192977905, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 767, Discriminator Loss: 0.1875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 768, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 769, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 770, Discriminator Loss: 0.2499997615814209, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 771, Discriminator Loss: 0.24999549984931946, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 772, Discriminator Loss: 0.23437500000000006, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 773, Discriminator Loss: 0.2695879237726331, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 774, Discriminator Loss: 0.21874649077653885, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 775, Discriminator Loss: 0.20312488824129105, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 776, Discriminator Loss: 0.20312465354800224, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 777, Discriminator Loss: 0.2499658688902855, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 778, Discriminator Loss: 0.2830998287536204, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 779, Discriminator Loss: 0.25483600329607725, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 780, Discriminator Loss: 0.2906984696164727, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 781, Discriminator Loss: 0.21030120085924864, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 782, Discriminator Loss: 0.2546499692834914, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 783, Discriminator Loss: 0.2571369702927768, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 784, Discriminator Loss: 0.3265582174062729, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 785, Discriminator Loss: 0.26557586155831814, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 786, Discriminator Loss: 0.2656240686774254, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 787, Discriminator Loss: 0.2656249813735485, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 788, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 789, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 790, Discriminator Loss: 0.265625, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 791, Discriminator Loss: 0.2656249850988388, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 792, Discriminator Loss: 0.265625, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 793, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 794, Discriminator Loss: 0.25, Generator Loss: [0.9687498807907104, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 795, Discriminator Loss: 0.265625, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 796, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 797, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 798, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 799, Discriminator Loss: 0.21875, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 800, Discriminator Loss: 0.2968769073486328, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 801, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 802, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 803, Discriminator Loss: 0.359375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 804, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 805, Discriminator Loss: 0.28125, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 806, Discriminator Loss: 0.3125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 807, Discriminator Loss: 0.2343742996454239, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 808, Discriminator Loss: 0.328125, Generator Loss: [0.9687457084655762, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 809, Discriminator Loss: 0.3125, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 810, Discriminator Loss: 0.28125, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 811, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 812, Discriminator Loss: 0.34375, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 813, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 814, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 815, Discriminator Loss: 0.3125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 816, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 817, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 818, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 819, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 820, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 821, Discriminator Loss: 0.203125, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 822, Discriminator Loss: 0.328125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 823, Discriminator Loss: 0.296875, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 824, Discriminator Loss: 0.28125, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 825, Discriminator Loss: 0.26561546325683594, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 826, Discriminator Loss: 0.296875, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 827, Discriminator Loss: 0.1875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 828, Discriminator Loss: 0.265625, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 829, Discriminator Loss: 0.359375, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 830, Discriminator Loss: 0.28125, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 831, Discriminator Loss: 0.1875, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 832, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 833, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 834, Discriminator Loss: 0.265625, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 835, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 836, Discriminator Loss: 0.234375, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 837, Discriminator Loss: 0.234375, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 838, Discriminator Loss: 0.3125, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 839, Discriminator Loss: 0.3125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 840, Discriminator Loss: 0.2968549132347107, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 841, Discriminator Loss: 0.25, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 842, Discriminator Loss: 0.28125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 843, Discriminator Loss: 0.28125, Generator Loss: [0.9685431122779846, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 844, Discriminator Loss: 0.26561588048934937, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 845, Discriminator Loss: 0.328125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 846, Discriminator Loss: 0.25, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 847, Discriminator Loss: 0.125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 848, Discriminator Loss: 0.34375, Generator Loss: [0.9992299675941467, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 849, Discriminator Loss: 0.28125, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 850, Discriminator Loss: 0.1875, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 851, Discriminator Loss: 0.21875, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 852, Discriminator Loss: 0.359375, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 853, Discriminator Loss: 0.265625, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 854, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 855, Discriminator Loss: 0.328125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 856, Discriminator Loss: 0.234375, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 857, Discriminator Loss: 0.34375, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 858, Discriminator Loss: 0.34375, Generator Loss: [0.8750002384185791, 0.125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 859, Discriminator Loss: 0.3125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 860, Discriminator Loss: 0.328125, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 861, Discriminator Loss: 0.1875, Generator Loss: [0.9477495551109314, 0.03125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 862, Discriminator Loss: 0.25003818050026894, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 863, Discriminator Loss: 0.2729603983461857, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 864, Discriminator Loss: 0.28125, Generator Loss: [0.9062501192092896, 0.09375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 865, Discriminator Loss: 0.328125, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 866, Discriminator Loss: 0.296875, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 867, Discriminator Loss: 0.21875, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 868, Discriminator Loss: 0.234375, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 869, Discriminator Loss: 0.3125, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 870, Discriminator Loss: 0.25, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 871, Discriminator Loss: 0.21875, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 872, Discriminator Loss: 0.21874995529651642, Generator Loss: [0.9374719858169556, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 873, Discriminator Loss: 0.234375, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 874, Discriminator Loss: 0.3125, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 875, Discriminator Loss: 0.28125, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 876, Discriminator Loss: 0.25, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 877, Discriminator Loss: 0.1875, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 878, Discriminator Loss: 0.21875, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 879, Discriminator Loss: 0.21875, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 880, Discriminator Loss: 0.29686596989631653, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 881, Discriminator Loss: 0.203125, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 882, Discriminator Loss: 0.203125, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 883, Discriminator Loss: 0.21875, Generator Loss: [0.9999631643295288, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 884, Discriminator Loss: 0.3125, Generator Loss: [0.875, 0.125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 885, Discriminator Loss: 0.3125, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 886, Discriminator Loss: 0.203125, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 887, Discriminator Loss: 0.28125, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 888, Discriminator Loss: 0.296875, Generator Loss: [0.875, 0.125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 889, Discriminator Loss: 0.25, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 890, Discriminator Loss: 0.296875, Generator Loss: [0.9676710367202759, 0.03125]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 891, Discriminator Loss: 0.28125, Generator Loss: [0.9984544515609741, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 892, Discriminator Loss: 0.28125003911554813, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 893, Discriminator Loss: 0.2831423133611679, Generator Loss: [0.84375, 0.15625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 894, Discriminator Loss: 0.2915012612938881, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 895, Discriminator Loss: 0.2343843299895525, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 896, Discriminator Loss: 0.31250179558992386, Generator Loss: [0.9999411702156067, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 897, Discriminator Loss: 0.281251460313797, Generator Loss: [0.9374990463256836, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 898, Discriminator Loss: 0.34375314228236675, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 899, Discriminator Loss: 0.18751457892358303, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 900, Discriminator Loss: 0.2657331246882677, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 901, Discriminator Loss: 0.2660603765398264, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 902, Discriminator Loss: 0.31257916428148746, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 903, Discriminator Loss: 0.20314767211675644, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 904, Discriminator Loss: 0.34376823902130127, Generator Loss: [0.9062502384185791, 0.09375]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 905, Discriminator Loss: 0.25003584660589695, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 906, Discriminator Loss: 0.29698606207966805, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 907, Discriminator Loss: 0.21894771046936512, Generator Loss: [0.9687497019767761, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 908, Discriminator Loss: 0.18758690357208252, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 909, Discriminator Loss: 0.28127454593777657, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 910, Discriminator Loss: 0.32814850471913815, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 911, Discriminator Loss: 0.26565077528357506, Generator Loss: [0.9060476422309875, 0.09375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 912, Discriminator Loss: 0.2969735153019428, Generator Loss: [0.84375, 0.15625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 913, Discriminator Loss: 0.2970335781574249, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 914, Discriminator Loss: 0.2969349194318056, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 915, Discriminator Loss: 0.25002037547528744, Generator Loss: [0.9687012434005737, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 916, Discriminator Loss: 0.3281386997550726, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 917, Discriminator Loss: 0.2040356993675232, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 918, Discriminator Loss: 0.25001170113682747, Generator Loss: [0.875, 0.125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 919, Discriminator Loss: 0.21876383759081364, Generator Loss: [0.875, 0.125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 920, Discriminator Loss: 0.32814258709549904, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 921, Discriminator Loss: 0.26564946398139, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 922, Discriminator Loss: 0.21877402439713478, Generator Loss: [0.8750284314155579, 0.125]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 923, Discriminator Loss: 0.23440613225102425, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 924, Discriminator Loss: 0.21878056228160858, Generator Loss: [0.9374986290931702, 0.0625]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 925, Discriminator Loss: 0.3281488064676523, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 926, Discriminator Loss: 0.26565244421362877, Generator Loss: [0.875, 0.125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 927, Discriminator Loss: 0.25001091323792934, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 928, Discriminator Loss: 0.2656328082084656, Generator Loss: [0.875, 0.125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 929, Discriminator Loss: 0.3593810684978962, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 930, Discriminator Loss: 0.32813010923564434, Generator Loss: [0.8749971389770508, 0.125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 931, Discriminator Loss: 0.20312969014048576, Generator Loss: [0.96875, 0.03125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 932, Discriminator Loss: 0.2656295169144869, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 933, Discriminator Loss: 0.25000448524951935, Generator Loss: [0.875, 0.125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 934, Discriminator Loss: 0.281254468485713, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 935, Discriminator Loss: 0.312504593282938, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 936, Discriminator Loss: 0.2812546342611313, Generator Loss: [0.84375, 0.15625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 937, Discriminator Loss: 0.2812546193599701, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 938, Discriminator Loss: 0.29693422466516495, Generator Loss: [0.9348189830780029, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 939, Discriminator Loss: 0.25, Generator Loss: [0.8450255393981934, 0.15625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 940, Discriminator Loss: 0.328125, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 941, Discriminator Loss: 0.25, Generator Loss: [0.84375, 0.15625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 942, Discriminator Loss: 0.296875, Generator Loss: [0.84375, 0.15625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 943, Discriminator Loss: 0.296875, Generator Loss: [0.9062390327453613, 0.09375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 944, Discriminator Loss: 0.296875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 945, Discriminator Loss: 0.203125, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 946, Discriminator Loss: 0.21875, Generator Loss: [1.0, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 947, Discriminator Loss: 0.265625, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 948, Discriminator Loss: 0.328125, Generator Loss: [0.8124642372131348, 0.1875]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 949, Discriminator Loss: 0.3125, Generator Loss: [0.8125, 0.1875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 950, Discriminator Loss: 0.265625, Generator Loss: [0.9062488079071045, 0.09375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 951, Discriminator Loss: 0.21875029802322388, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 952, Discriminator Loss: 0.23525374755263329, Generator Loss: [0.8749995231628418, 0.125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 953, Discriminator Loss: 0.296875, Generator Loss: [0.875, 0.125]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 954, Discriminator Loss: 0.20855847001075745, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 955, Discriminator Loss: 0.234375, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 956, Discriminator Loss: 0.265625, Generator Loss: [0.9063350558280945, 0.09375]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 957, Discriminator Loss: 0.28125, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 958, Discriminator Loss: 0.265625, Generator Loss: [0.8666696548461914, 0.125]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoch 959, Discriminator Loss: 0.3281251788139343, Generator Loss: [0.84375, 0.15625]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 960, Discriminator Loss: 0.377806693315506, Generator Loss: [0.8125, 0.1875]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch 961, Discriminator Loss: 0.3596978932619095, Generator Loss: [0.84375, 0.15625]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 962, Discriminator Loss: 0.39184799790382385, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 963, Discriminator Loss: 0.5312495529651642, Generator Loss: [0.84375, 0.15625]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 964, Discriminator Loss: 0.34375, Generator Loss: [0.9375, 0.0625]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 965, Discriminator Loss: 0.4843749403953552, Generator Loss: [0.75, 0.25]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 966, Discriminator Loss: 0.390625, Generator Loss: [0.8125, 0.1875]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 967, Discriminator Loss: 0.4375, Generator Loss: [0.90625, 0.09375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 968, Discriminator Loss: 0.453125, Generator Loss: [0.71875, 0.28125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 969, Discriminator Loss: 0.453125, Generator Loss: [0.8125, 0.1875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 970, Discriminator Loss: 0.46875, Generator Loss: [0.84375, 0.15625]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 971, Discriminator Loss: 0.4375, Generator Loss: [0.6879996061325073, 0.3125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 972, Discriminator Loss: 0.4375, Generator Loss: [0.84375, 0.15625]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 973, Discriminator Loss: 0.484375, Generator Loss: [0.65625, 0.34375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 974, Discriminator Loss: 0.46875, Generator Loss: [0.6875, 0.3125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 975, Discriminator Loss: 0.40625, Generator Loss: [0.78125, 0.21875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 976, Discriminator Loss: 0.515625, Generator Loss: [0.75, 0.25]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 977, Discriminator Loss: 0.46875, Generator Loss: [0.75, 0.25]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 978, Discriminator Loss: 0.48437339067459106, Generator Loss: [0.8125, 0.1875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 979, Discriminator Loss: 0.46875, Generator Loss: [0.65625, 0.34375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 980, Discriminator Loss: 0.5, Generator Loss: [0.84375, 0.15625]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 981, Discriminator Loss: 0.40625, Generator Loss: [0.65625, 0.34375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 982, Discriminator Loss: 0.421875, Generator Loss: [0.71875, 0.28125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 983, Discriminator Loss: 0.453125, Generator Loss: [0.71875, 0.28125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 984, Discriminator Loss: 0.453125, Generator Loss: [0.71875, 0.28125]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 985, Discriminator Loss: 0.421875, Generator Loss: [0.6875, 0.3125]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 986, Discriminator Loss: 0.453125, Generator Loss: [0.65625, 0.34375]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 987, Discriminator Loss: 0.390625, Generator Loss: [0.59375, 0.40625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 988, Discriminator Loss: 0.4375, Generator Loss: [0.78125, 0.21875]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 989, Discriminator Loss: 0.453125, Generator Loss: [0.65625, 0.34375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 990, Discriminator Loss: 0.44874049723148346, Generator Loss: [0.71875, 0.28125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 991, Discriminator Loss: 0.5, Generator Loss: [0.71875, 0.28125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 992, Discriminator Loss: 0.421875, Generator Loss: [0.5625, 0.4375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 993, Discriminator Loss: 0.484375, Generator Loss: [0.78125, 0.21875]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 994, Discriminator Loss: 0.546875, Generator Loss: [0.75, 0.25]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 995, Discriminator Loss: 0.5, Generator Loss: [0.59375, 0.40625]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 996, Discriminator Loss: 0.484375, Generator Loss: [0.6875, 0.3125]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 997, Discriminator Loss: 0.53125, Generator Loss: [0.5625, 0.4375]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 998, Discriminator Loss: 0.515625, Generator Loss: [0.59375, 0.40625]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 999, Discriminator Loss: 0.453125, Generator Loss: [0.5625, 0.4375]\n"
     ]
    }
   ],
   "source": [
    "# Define training loop\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "num_samples = bars_df_scaled.shape[0]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train discriminator\n",
    "    # Sample real data\n",
    "    idx = np.random.choice(num_samples, batch_size, replace=False)\n",
    "    real_data = bars_df_scaled[idx]\n",
    "    # Generate fake data\n",
    "    noise = random_walk_noise\n",
    "    fake_data = build_generator.predict(random_walk_noise)\n",
    "    # Train discriminator\n",
    "    d_loss_real = build_discriminator.train_on_batch(real_data, np.ones((batch_size, 1)))\n",
    "    d_loss_fake = build_discriminator.train_on_batch(fake_data, np.zeros((batch_size, 1)))\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "    \n",
    "    # Train generator\n",
    "    noise = np.random.normal(0, 1, (batch_size, input_shape))\n",
    "    g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch}, Discriminator Loss: {d_loss}, Generator Loss: {g_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create alpaca object for testing\n",
    "\n",
    "timeframe = TimeFrame(1, TimeFrameUnit.Day)\n",
    "symbol = 'SPY'\n",
    "start = datetime.utcnow() - timedelta(days=10)\n",
    "end=datetime.utcnow() - timedelta(days=3)\n",
    "request = StockBarsRequest(symbol_or_symbols=symbol, start=start, end=end, timeframe=timeframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3 entries, 2024-02-14 00:00:00-05:00 to 2024-02-16 00:00:00-05:00\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   open         3 non-null      float64\n",
      " 1   high         3 non-null      float64\n",
      " 2   low          3 non-null      float64\n",
      " 3   close        3 non-null      float64\n",
      " 4   volume       3 non-null      float64\n",
      " 5   trade_count  3 non-null      float64\n",
      " 6   vwap         3 non-null      float64\n",
      " 7   pct_change   3 non-null      float64\n",
      " 8   high %       3 non-null      float64\n",
      " 9   low %        3 non-null      float64\n",
      " 10  open %       3 non-null      float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 288.0 bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>high %</th>\n",
       "      <th>low %</th>\n",
       "      <th>open %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-02-14 00:00:00-05:00</th>\n",
       "      <td>496.79</td>\n",
       "      <td>499.07</td>\n",
       "      <td>494.400</td>\n",
       "      <td>498.57</td>\n",
       "      <td>68387827.0</td>\n",
       "      <td>536843.0</td>\n",
       "      <td>496.719466</td>\n",
       "      <td>0.009088</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>-0.008364</td>\n",
       "      <td>-0.003570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-15 00:00:00-05:00</th>\n",
       "      <td>499.29</td>\n",
       "      <td>502.20</td>\n",
       "      <td>498.795</td>\n",
       "      <td>502.01</td>\n",
       "      <td>61682960.0</td>\n",
       "      <td>516093.0</td>\n",
       "      <td>500.763897</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>-0.006404</td>\n",
       "      <td>-0.005418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-16 00:00:00-05:00</th>\n",
       "      <td>501.70</td>\n",
       "      <td>502.87</td>\n",
       "      <td>498.750</td>\n",
       "      <td>499.51</td>\n",
       "      <td>75481032.0</td>\n",
       "      <td>531239.0</td>\n",
       "      <td>500.924740</td>\n",
       "      <td>-0.004980</td>\n",
       "      <td>0.006727</td>\n",
       "      <td>-0.001521</td>\n",
       "      <td>0.004384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             open    high      low   close      volume  \\\n",
       "timestamp                                                                \n",
       "2024-02-14 00:00:00-05:00  496.79  499.07  494.400  498.57  68387827.0   \n",
       "2024-02-15 00:00:00-05:00  499.29  502.20  498.795  502.01  61682960.0   \n",
       "2024-02-16 00:00:00-05:00  501.70  502.87  498.750  499.51  75481032.0   \n",
       "\n",
       "                           trade_count        vwap  pct_change    high %  \\\n",
       "timestamp                                                                  \n",
       "2024-02-14 00:00:00-05:00     536843.0  496.719466    0.009088  0.001003   \n",
       "2024-02-15 00:00:00-05:00     516093.0  500.763897    0.006900  0.000378   \n",
       "2024-02-16 00:00:00-05:00     531239.0  500.924740   -0.004980  0.006727   \n",
       "\n",
       "                              low %    open %  \n",
       "timestamp                                      \n",
       "2024-02-14 00:00:00-05:00 -0.008364 -0.003570  \n",
       "2024-02-15 00:00:00-05:00 -0.006404 -0.005418  \n",
       "2024-02-16 00:00:00-05:00 -0.001521  0.004384  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create df for testing\n",
    "\n",
    "test_df = client.get_stock_bars(request).df.tz_convert('America/New_York', level=1)\n",
    "\n",
    "# data preprocessing for testing\n",
    "\n",
    "# pct_change is profit from last close\n",
    "test_df[\"pct_change\"] = test_df[\"close\"].pct_change()\n",
    "# signal for when we want to be in or out of a stock\n",
    "#bars_df[\"signal\"] = np.where(bars_df[\"pct_change\"] > 0, 1.0, 0.0)\n",
    "# reaction is the signal diff\n",
    "#bars_df[\"reaction\"] = bars_df[\"signal\"].diff()\n",
    "# action is if we could perfectly predict the next close\n",
    "#bars_df[\"action\"] = bars_df[\"reaction\"].shift(-1)\n",
    "# these values are the high, low, and open as a percentage of the current close\n",
    "test_df[\"high %\"] = (test_df[\"high\"] - test_df[\"close\"])/test_df[\"close\"]\n",
    "test_df[\"low %\"] = (test_df[\"low\"] - test_df[\"close\"])/test_df[\"close\"]\n",
    "test_df[\"open %\"] = (test_df[\"open\"] - test_df[\"close\"])/test_df[\"close\"]\n",
    "\n",
    "# set timestamp as index, drop nan\n",
    "\n",
    "test_df = test_df.droplevel(level=0).dropna()\n",
    "\n",
    "test_df.info()\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.23215904 -1.39479259 -1.41415739 -1.00570938 -0.02297675  1.0022861\n",
      "  -1.41340788  0.87667542 -0.59500317 -1.01977988 -0.47862307]\n",
      " [ 0.01496549  0.49512118  0.71799415  1.36390724 -1.21309484 -1.3651841\n",
      "   0.66536851  0.52269306 -0.81356926 -0.33865985 -0.91315971]\n",
      " [ 1.21719355  0.89967141  0.69616325 -0.35819786  1.23607159  0.362898\n",
      "   0.74803938 -1.39936849  1.40857243  1.35843973  1.39178278]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize test data set\n",
    "\n",
    "test_df_scaled = scaler.fit_transform(test_df)\n",
    "\n",
    "print(test_df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[0 0]\n",
      " [2 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.50      0.17      0.25         3\n",
      "weighted avg       1.00      0.33      0.50         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 21:18:06.454444: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "/Users/ebrown/anaconda3/envs/GAN_kernel/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ebrown/anaconda3/envs/GAN_kernel/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ebrown/anaconda3/envs/GAN_kernel/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluate discriminator on test data\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "discriminator_predictions = build_discriminator.predict(test_df_scaled)\n",
    "\n",
    "print(confusion_matrix(np.ones(len(test_df_scaled)),discriminator_predictions))\n",
    "print(classification_report(np.ones(len(test_df_scaled)),discriminator_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "generated_data = build_generator.predict(random_walk_noise)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(generated_data[:4], label=\"generated data\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original df shape (3, 11)\n",
      "generated df shape (32, 11)\n",
      "Original dataframe summary statistics:\n",
      "[[-1.23215904 -1.39479259 -1.41415739 -1.00570938 -0.02297675  1.0022861\n",
      "  -1.41340788  0.87667542 -0.59500317 -1.01977988 -0.47862307]\n",
      " [ 0.01496549  0.49512118  0.71799415  1.36390724 -1.21309484 -1.3651841\n",
      "   0.66536851  0.52269306 -0.81356926 -0.33865985 -0.91315971]\n",
      " [ 1.21719355  0.89967141  0.69616325 -0.35819786  1.23607159  0.362898\n",
      "   0.74803938 -1.39936849  1.40857243  1.35843973  1.39178278]]\n"
     ]
    }
   ],
   "source": [
    "print(\"original df shape\", test_df_scaled.shape)\n",
    "print(\"generated df shape\", generated_data.shape)\n",
    "\n",
    "print(\"Original dataframe summary statistics:\")\n",
    "print((test_df_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated dataframe summary statistics:\n",
      "              0             1             2             3             4   \\\n",
      "0   1.000000e+00  9.542911e-05  2.384970e-03  2.787823e-03  8.970282e-01   \n",
      "1   1.000000e+00  1.885809e-16  5.090092e-01  9.999965e-01  1.000000e+00   \n",
      "2   1.000000e+00  2.990484e-05  1.000000e+00  1.000000e+00  2.563813e-12   \n",
      "3   1.841903e-12  1.972008e-07  1.467661e-24  1.299798e-26  9.999996e-01   \n",
      "4   1.000000e+00  9.997774e-01  8.007740e-01  8.311570e-02  1.504658e-08   \n",
      "5   1.000000e+00  1.523944e-13  1.660767e-09  1.207429e-08  9.983532e-01   \n",
      "6   1.000000e+00  9.958693e-01  1.000000e+00  1.000000e+00  7.970783e-30   \n",
      "7   1.000000e+00  9.659131e-01  1.000000e+00  1.000000e+00  6.861977e-21   \n",
      "8   1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  2.206549e-26   \n",
      "9   6.459171e-12  1.000000e+00  6.799999e-17  4.001357e-25  2.719022e-12   \n",
      "10  0.000000e+00  1.000000e+00  3.295828e-30  0.000000e+00  4.279485e-11   \n",
      "11  0.000000e+00  1.000000e+00  1.359469e-08  1.382766e-21  1.425819e-25   \n",
      "12  4.099978e-35  1.000000e+00  9.999845e-01  7.063876e-08  4.102927e-31   \n",
      "13  6.455442e-19  1.000000e+00  9.999995e-01  1.694174e-11  0.000000e+00   \n",
      "14  0.000000e+00  1.000000e+00  3.044273e-15  2.249837e-34  0.000000e+00   \n",
      "15  0.000000e+00  1.000000e+00  1.278916e-09  1.457479e-32  0.000000e+00   \n",
      "16  0.000000e+00  1.000000e+00  1.000000e+00  3.136856e-11  0.000000e+00   \n",
      "17  0.000000e+00  1.000000e+00  3.618120e-09  3.102771e-26  0.000000e+00   \n",
      "18  0.000000e+00  1.000000e+00  8.008205e-03  5.934250e-19  0.000000e+00   \n",
      "19  0.000000e+00  1.000000e+00  3.149183e-04  6.155084e-14  1.237072e-27   \n",
      "20  0.000000e+00  1.000000e+00  5.077767e-04  1.036917e-09  8.627073e-19   \n",
      "21  0.000000e+00  1.000000e+00  6.608912e-32  0.000000e+00  2.142311e-10   \n",
      "22  0.000000e+00  1.000000e+00  2.825897e-08  1.849291e-17  3.792486e-25   \n",
      "23  1.375513e-26  1.000000e+00  9.468763e-01  2.256071e-05  3.870720e-28   \n",
      "24  0.000000e+00  1.000000e+00  5.617079e-21  2.853832e-33  7.799986e-32   \n",
      "25  3.405942e-29  1.000000e+00  1.000000e+00  9.999990e-01  0.000000e+00   \n",
      "26  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
      "27  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
      "28  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
      "29  5.065439e-14  1.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
      "30  9.999994e-01  1.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
      "31  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
      "\n",
      "              5             6             7             8             9   \\\n",
      "0   9.886070e-06  9.999942e-01  1.439944e-12  1.347329e-08  9.938074e-01   \n",
      "1   1.000000e+00  1.000000e+00  5.135109e-37  3.606092e-20  1.000000e+00   \n",
      "2   1.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00   \n",
      "3   6.128159e-27  5.693149e-19  1.000000e+00  1.000000e+00  5.906935e-02   \n",
      "4   2.350547e-16  9.791581e-01  3.234501e-02  1.696251e-07  8.711330e-01   \n",
      "5   4.082634e-11  9.999989e-01  1.326034e-22  3.782229e-17  1.000000e+00   \n",
      "6   1.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00   \n",
      "7   9.999994e-01  1.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00   \n",
      "8   2.029631e-14  1.000000e+00  1.638939e-22  5.334549e-33  9.999976e-01   \n",
      "9   0.000000e+00  3.748683e-28  1.000000e+00  1.000000e+00  3.805351e-08   \n",
      "10  0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  7.371008e-23   \n",
      "11  0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  1.138526e-29   \n",
      "12  0.000000e+00  6.292367e-36  1.000000e+00  1.000000e+00  5.797799e-27   \n",
      "13  0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  1.107198e-24   \n",
      "14  0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  1.574849e-29   \n",
      "15  0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  1.110780e-34   \n",
      "16  0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
      "17  0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
      "18  0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
      "19  0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  8.308717e-31   \n",
      "20  2.442236e-22  0.000000e+00  1.000000e+00  1.000000e+00  1.062157e-32   \n",
      "21  0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  1.345088e-29   \n",
      "22  0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  2.572978e-31   \n",
      "23  0.000000e+00  8.890851e-33  1.000000e+00  1.000000e+00  5.117614e-19   \n",
      "24  0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  7.768934e-37   \n",
      "25  0.000000e+00  4.654418e-34  1.000000e+00  1.000000e+00  1.462010e-26   \n",
      "26  0.000000e+00  1.703406e-02  1.000000e+00  9.999529e-01  7.993047e-21   \n",
      "27  0.000000e+00  9.148909e-06  1.000000e+00  1.000000e+00  1.008554e-24   \n",
      "28  0.000000e+00  4.241103e-09  1.000000e+00  9.999995e-01  3.931610e-23   \n",
      "29  0.000000e+00  2.524800e-24  1.000000e+00  1.000000e+00  9.459025e-26   \n",
      "30  8.297397e-34  8.341272e-05  1.000000e+00  1.000000e+00  4.017865e-23   \n",
      "31  0.000000e+00  1.000000e+00  1.000000e+00  5.107966e-13  5.163676e-20   \n",
      "\n",
      "              10  \n",
      "0   5.780591e-06  \n",
      "1   1.484174e-17  \n",
      "2   0.000000e+00  \n",
      "3   1.000000e+00  \n",
      "4   1.378830e-04  \n",
      "5   1.066226e-11  \n",
      "6   0.000000e+00  \n",
      "7   0.000000e+00  \n",
      "8   1.832212e-26  \n",
      "9   1.000000e+00  \n",
      "10  1.000000e+00  \n",
      "11  1.000000e+00  \n",
      "12  1.000000e+00  \n",
      "13  1.000000e+00  \n",
      "14  1.000000e+00  \n",
      "15  1.000000e+00  \n",
      "16  1.000000e+00  \n",
      "17  1.000000e+00  \n",
      "18  1.000000e+00  \n",
      "19  1.000000e+00  \n",
      "20  1.000000e+00  \n",
      "21  1.000000e+00  \n",
      "22  1.000000e+00  \n",
      "23  1.000000e+00  \n",
      "24  1.000000e+00  \n",
      "25  1.000000e+00  \n",
      "26  8.880147e-01  \n",
      "27  9.998092e-01  \n",
      "28  9.999233e-01  \n",
      "29  1.000000e+00  \n",
      "30  9.999014e-01  \n",
      "31  8.706590e-14  \n"
     ]
    }
   ],
   "source": [
    "print(\"Generated dataframe summary statistics:\")\n",
    "print(pd.DataFrame(generated_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>501.264618</td>\n",
       "      <td>501.380157</td>\n",
       "      <td>497.319916</td>\n",
       "      <td>500.034058</td>\n",
       "      <td>73570936.0</td>\n",
       "      <td>528058.4375</td>\n",
       "      <td>501.414948</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.001535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>501.264618</td>\n",
       "      <td>501.380005</td>\n",
       "      <td>498.364227</td>\n",
       "      <td>501.481720</td>\n",
       "      <td>74151056.0</td>\n",
       "      <td>536822.9375</td>\n",
       "      <td>501.414948</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>-0.002553</td>\n",
       "      <td>-0.001535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>501.264618</td>\n",
       "      <td>501.380035</td>\n",
       "      <td>499.376312</td>\n",
       "      <td>501.481720</td>\n",
       "      <td>68517272.0</td>\n",
       "      <td>536822.9375</td>\n",
       "      <td>501.414948</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>-0.002553</td>\n",
       "      <td>-0.001535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>499.260010</td>\n",
       "      <td>501.380005</td>\n",
       "      <td>497.315002</td>\n",
       "      <td>500.029999</td>\n",
       "      <td>74151056.0</td>\n",
       "      <td>528058.3125</td>\n",
       "      <td>499.469360</td>\n",
       "      <td>0.009850</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>-0.005260</td>\n",
       "      <td>0.002718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>501.264618</td>\n",
       "      <td>503.035797</td>\n",
       "      <td>498.965637</td>\n",
       "      <td>500.150665</td>\n",
       "      <td>68517272.0</td>\n",
       "      <td>528058.3125</td>\n",
       "      <td>501.374390</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>-0.002924</td>\n",
       "      <td>-0.001534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1           2           3           4            5   \\\n",
       "0  501.264618  501.380157  497.319916  500.034058  73570936.0  528058.4375   \n",
       "1  501.264618  501.380005  498.364227  501.481720  74151056.0  536822.9375   \n",
       "2  501.264618  501.380035  499.376312  501.481720  68517272.0  536822.9375   \n",
       "3  499.260010  501.380005  497.315002  500.029999  74151056.0  528058.3125   \n",
       "4  501.264618  503.035797  498.965637  500.150665  68517272.0  528058.3125   \n",
       "\n",
       "           6         7         8         9         10  \n",
       "0  501.414948  0.003669  0.002703 -0.002571 -0.001535  \n",
       "1  501.414948  0.003669  0.002703 -0.002553 -0.001535  \n",
       "2  501.414948  0.003669  0.002703 -0.002553 -0.001535  \n",
       "3  499.469360  0.009850  0.005559 -0.005260  0.002718  \n",
       "4  501.374390  0.003869  0.002703 -0.002924 -0.001534  "
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data_inverse = scaler.inverse_transform(generated_data)\n",
    "generated_data_df = pd.DataFrame(generated_data_inverse)\n",
    "generated_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SPY</th>\n",
       "      <th>2024-02-20 00:00:00-05:00</th>\n",
       "      <td>497.72</td>\n",
       "      <td>498.41</td>\n",
       "      <td>494.45</td>\n",
       "      <td>496.76</td>\n",
       "      <td>71736740.0</td>\n",
       "      <td>595486.0</td>\n",
       "      <td>496.441094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-21 00:00:00-05:00</th>\n",
       "      <td>495.42</td>\n",
       "      <td>497.37</td>\n",
       "      <td>493.56</td>\n",
       "      <td>497.21</td>\n",
       "      <td>59381397.0</td>\n",
       "      <td>497559.0</td>\n",
       "      <td>495.813866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    open    high     low   close      volume  \\\n",
       "symbol timestamp                                                               \n",
       "SPY    2024-02-20 00:00:00-05:00  497.72  498.41  494.45  496.76  71736740.0   \n",
       "       2024-02-21 00:00:00-05:00  495.42  497.37  493.56  497.21  59381397.0   \n",
       "\n",
       "                                  trade_count        vwap  \n",
       "symbol timestamp                                           \n",
       "SPY    2024-02-20 00:00:00-05:00     595486.0  496.441094  \n",
       "       2024-02-21 00:00:00-05:00     497559.0  495.813866  "
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create alpaca object for testing\n",
    "\n",
    "timeframe = TimeFrame(1, TimeFrameUnit.Day)\n",
    "symbol = 'SPY'\n",
    "start = datetime.utcnow() - timedelta(days=3)\n",
    "end=datetime.utcnow() - timedelta(days=1)\n",
    "request = StockBarsRequest(symbol_or_symbols=symbol, start=start, end=end, timeframe=timeframe)\n",
    "\n",
    "current_df = client.get_stock_bars(request).df.tz_convert('America/New_York', level=1)\n",
    "current_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define constants\n",
    "\n",
    "# latent_dim = 100\n",
    "# input_shape = bars_df.shape[1]\n",
    "# output_shape = bars_df.shape[1]\n",
    "# num_samples = 1000\n",
    "# gaussian_noise = np.random.normal(0,1,size=(num_samples, latent_dim))\n",
    "# random_walk_noise = np.cumsum(gaussian_noise,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define model building functions\n",
    "\n",
    "# def build_generator(num_layers,layer_size,activation,output_activation):\n",
    "#     model = models.Sequential()\n",
    "#     model.add(layers.Dense(layer_size, activation = activation, input_dim=num_layers))\n",
    "\n",
    "#     for _ in range(num_layers-1):\n",
    "#         model.add(layers.Dense(layer_size, activation = activation))\n",
    "\n",
    "#     model.add(layers.Dense(output_shape,activation = output_activation))\n",
    "\n",
    "#     pass\n",
    "\n",
    "# # def build_discriminator(layers,layer_size,activation):\n",
    "\n",
    "# def build_discriminator(num_layers,layer_size,activation):\n",
    "#     model = models.Sequential()\n",
    "#     model.add(layers.Dense(layer_size, activation = activation, input_dim = input_shape))\n",
    "\n",
    "#     for _ in range(num_layers - 1):\n",
    "#         model.add(layers.Dense(layer_size, activation = activation))\n",
    "\n",
    "#     model.add(layers.Dense(1))\n",
    "\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data set\n",
    "\n",
    "scaler = StandardScaler()\n",
    "bars_df_scaled = scaler.fit_transform(bars_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class GeneratorWrapper(BaseEstimator):\n",
    "    def __init__(self, num_layers, layer_size, activation, output_activation):\n",
    "        self.num_layers = num_layers\n",
    "        self.layer_size = layer_size\n",
    "        self.activation = activation\n",
    "        self.output_activation = output_activation\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Build generator model\n",
    "        self.model = build_generator(self.num_layers, self.layer_size, self.activation, self.output_activation)\n",
    "        # Compile the model\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        # Fit the model\n",
    "        self.model.fit(X, X, epochs=3, batch_size=64, verbose=0)  # Assuming autoencoder-like training\n",
    "        return self\n",
    "\n",
    "class DiscriminatorWrapper(BaseEstimator):\n",
    "    def __init__(self, num_layers=2, layer_size=128, activation='relu'):\n",
    "        self.num_layers = num_layers\n",
    "        self.layer_size = layer_size\n",
    "        self.activation = activation\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Build discriminator model\n",
    "        self.model = build_discriminator(self.num_layers, self.layer_size, self.activation)\n",
    "        # Compile the model\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        # Fit the model\n",
    "        self.model.fit(X, y, epochs=3, batch_size=64, verbose=0)  # Assuming binary classification\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform girdsearch for generator\n",
    "\n",
    "# generator_search = GridSearchCV(estimator=build_generator, param_grid=generator_grid, cv = 3)\n",
    "# generator_search.fit(random_walk_noise, bars_df_scaled)\n",
    "# best_generator_params = generator_search.best_params_\n",
    "\n",
    "# # get the best output layer activation from gridsearch\n",
    "\n",
    "# output_activation = best_generator_params.pop(\"output_activation\")\n",
    "\n",
    "# # Build the generator with the best parameters\n",
    "# generator = build_generator(latent_dim, output_shape, output_activation, **best_generator_params)\n",
    "\n",
    "# # Perform grid search for discriminator\n",
    "# discriminator_search = GridSearchCV(estimator=build_discriminator, param_grid=discriminator_grid, cv=3)\n",
    "# discriminator_search.fit(random_walk_noise,bars_df_scaled)\n",
    "# best_discriminator_params = discriminator_search.best_params_\n",
    "\n",
    "# # Build the discriminator with the best parameters\n",
    "# discriminator = build_discriminator(**best_discriminator_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 4 required positional arguments: 'num_layers', 'layer_size', 'activation', and 'output_activation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ebrown/Desktop/Price_Action_Reloaded/Predictions/prediction_EB.ipynb Cell 31\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ebrown/Desktop/Price_Action_Reloaded/Predictions/prediction_EB.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create GridSearchCV instance for the generator\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ebrown/Desktop/Price_Action_Reloaded/Predictions/prediction_EB.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m generator_search \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mGeneratorWrapper(), param_grid\u001b[39m=\u001b[39mgenerator_grid, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ebrown/Desktop/Price_Action_Reloaded/Predictions/prediction_EB.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m generator_search\u001b[39m.\u001b[39mfit(random_walk_noise, bars_df_scaled)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ebrown/Desktop/Price_Action_Reloaded/Predictions/prediction_EB.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m best_generator_params \u001b[39m=\u001b[39m generator_search\u001b[39m.\u001b[39mbest_params_\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 4 required positional arguments: 'num_layers', 'layer_size', 'activation', and 'output_activation'"
     ]
    }
   ],
   "source": [
    "# Create GridSearchCV instance for the generator\n",
    "generator_search = GridSearchCV(estimator=GeneratorWrapper(), param_grid=generator_grid, cv=3)\n",
    "generator_search.fit(random_walk_noise, bars_df_scaled)\n",
    "best_generator_params = generator_search.best_params_\n",
    "\n",
    "# Create GridSearchCV instance for the discriminator\n",
    "discriminator_search = GridSearchCV(estimator=DiscriminatorWrapper(), param_grid=discriminator_grid, cv=3)\n",
    "discriminator_search.fit(bars_df_scaled)\n",
    "best_discriminator_params = discriminator_search.best_params_\n",
    "\n",
    "print(\"Best parameters for the generator:\", best_generator_params)\n",
    "print(\"Best parameters for the discriminator:\", best_discriminator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
